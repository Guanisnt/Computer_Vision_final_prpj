{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e71083b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 02:20:14.031038: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-03 02:20:14.043172: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767378014.057266    1790 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767378014.061325    1790 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-03 02:20:14.076404: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a65e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_FOLDER = '/mnt/f/course/computer_vision/final_proj_img/final_proj_img/pic/'\n",
    "TXT_FOLDER = '/mnt/f/course/computer_vision/txt/'\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d846f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading name.txt from: /mnt/f/course/computer_vision/txt/name.txt\n",
      "Detected 50 classes.\n",
      "Warning: File not found: /mnt/f/course/computer_vision/final_proj_img/final_proj_img/pic/Planet/Planet_199.jpg\n",
      "Warning: File not found: /mnt/f/course/computer_vision/final_proj_img/final_proj_img/pic/Planet/Planet_200.jpg\n",
      "Total missing files: 2\n",
      "Training Data: 6999 images\n",
      "Testing Data: 2999 images\n",
      "Ready for ResNet/VGG training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767378037.381348    1790 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "def load_dataset_from_name_txt(img_folder, txt_folder):\n",
    "    filename_list = []\n",
    "    class_name_list = []\n",
    "    \n",
    "    # 1. 讀取 name.txt\n",
    "    # 格式: \"AncestorDinoArt_001.jpg AncestorDinoArt\"\n",
    "    name_txt_path = os.path.join(txt_folder, 'name.txt')\n",
    "    print(f\"Reading name.txt from: {name_txt_path}\")\n",
    "    \n",
    "    with open(name_txt_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                filename_list.append(parts[0])      # e.g., AncestorDinoArt_001.jpg\n",
    "                class_name_list.append(parts[1])    # e.g., AncestorDinoArt (這也是資料夾名稱)\n",
    "    \n",
    "    # 2. 建立標籤對照表\n",
    "    unique_classes = sorted(list(set(class_name_list)))\n",
    "    class_to_idx = {name: i for i, name in enumerate(unique_classes)}\n",
    "    print(f\"Detected {len(unique_classes)} classes.\")\n",
    "\n",
    "    # 3. 讀取 query.txt (注意：這裡假設 query.txt 是 1-based index)\n",
    "    query_txt_path = os.path.join(txt_folder, 'query.txt')\n",
    "    with open(query_txt_path, 'r') as f:\n",
    "        test_indices = set([int(line.strip()) - 1 for line in f])\n",
    "\n",
    "    # 4. 分裝 Train / Test\n",
    "    train_paths = []\n",
    "    train_labels = []\n",
    "    test_paths = []\n",
    "    test_labels = []\n",
    "\n",
    "    missing_count = 0\n",
    "\n",
    "    for idx, filename in enumerate(filename_list):\n",
    "        class_name = class_name_list[idx]\n",
    "        \n",
    "        # --- [關鍵修正] 路徑加入類別資料夾 ---\n",
    "        # 舊路徑: pic/AncestorDinoArt_001.jpg (錯誤)\n",
    "        # 新路徑: pic/AncestorDinoArt/AncestorDinoArt_001.jpg (正確)\n",
    "        full_path = os.path.join(img_folder, class_name, filename)\n",
    "        \n",
    "        label_idx = class_to_idx[class_name]\n",
    "        \n",
    "        # 檢查檔案是否存在\n",
    "        if not os.path.exists(full_path):\n",
    "            if missing_count < 5: # 只印出前 5 個錯誤以免洗版\n",
    "                print(f\"Warning: File not found: {full_path}\")\n",
    "            missing_count += 1\n",
    "            continue\n",
    "\n",
    "        if idx in test_indices:\n",
    "            test_paths.append(full_path)\n",
    "            test_labels.append(label_idx)\n",
    "        else:\n",
    "            train_paths.append(full_path)\n",
    "            train_labels.append(label_idx)\n",
    "\n",
    "    if missing_count > 0:\n",
    "        print(f\"Total missing files: {missing_count}\")\n",
    "    else:\n",
    "        print(\"All files found successfully!\")\n",
    "\n",
    "    return (train_paths, train_labels), (test_paths, test_labels), len(unique_classes)\n",
    "\n",
    "# --- 執行讀取測試 ---\n",
    "(tr_x, tr_y), (te_x, te_y), num_classes = load_dataset_from_name_txt(IMG_FOLDER, TXT_FOLDER)\n",
    "\n",
    "print(f\"Training Data: {len(tr_x)} images\")\n",
    "print(f\"Testing Data: {len(te_x)} images\")\n",
    "\n",
    "# 建立 tf.data Pipeline\n",
    "def preprocess(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    # 將標籤轉換為 one-hot 編碼\n",
    "    label_onehot = tf.one_hot(label, depth=num_classes)\n",
    "    return img, label_onehot\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((tr_x, tr_y))\n",
    "train_ds = train_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((te_x, te_y))\n",
    "test_ds = test_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Ready for ResNet/VGG training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d77392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50, ResNet101, ResNet152, VGG16, VGG19\n",
    "from tensorflow.keras import layers, models, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0817077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_name):\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    if model_name == 'ResNet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    elif model_name == 'ResNet101':\n",
    "        base_model = ResNet101(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    elif model_name == 'ResNet152':\n",
    "        base_model = ResNet152(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    elif model_name == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    elif model_name == 'VGG19':\n",
    "        base_model = VGG19(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=base_model.input, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c29b8606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VGG16\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guan/cuda_test/tf-venv/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(None, 224, 224, 3))\n",
      "  warnings.warn(msg)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767378039.541448    1885 service.cc:148] XLA service 0x7dddf400ee70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1767378039.541482    1885 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2026-01-03 02:20:39.594967: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1767378039.810386    1885 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2026-01-03 02:20:40.482749: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1642', 68 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2026-01-03 02:20:40.546727: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1642', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2026-01-03 02:20:40.919607: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1642', 60 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2026-01-03 02:20:43.555271: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/219\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 99ms/step - accuracy: 0.0391 - auc: 0.4007 - f1_score: 0.0014 - loss: 4.2434 - precision: 0.0000e+00 - recall: 0.0000e+00         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767378052.392776    1885 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.0484 - auc: 0.4991 - f1_score: 0.0056 - loss: 4.4758 - precision: 0.0512 - recall: 0.0096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 02:21:14.681230: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1339', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2026-01-03 02:21:14.714076: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1642', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2026-01-03 02:21:14.797384: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1642', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2026-01-03 02:21:14.814500: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1642', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2026-01-03 02:21:16.393773: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.75GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.0482 - auc: 0.4987 - f1_score: 0.0056 - loss: 4.4750 - precision: 0.0511 - recall: 0.0096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 02:21:24.265636: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2026-01-03 02:21:33.818151: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 194ms/step - accuracy: 0.0480 - auc: 0.4983 - f1_score: 0.0055 - loss: 4.4742 - precision: 0.0511 - recall: 0.0096 - val_accuracy: 0.0200 - val_auc: 0.5025 - val_f1_score: 7.9103e-04 - val_loss: 3.9105 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 130ms/step - accuracy: 0.0959 - auc: 0.5988 - f1_score: 0.0058 - loss: 3.8995 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0397 - val_auc: 0.5093 - val_f1_score: 0.0264 - val_loss: 3.9088 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 132ms/step - accuracy: 0.0964 - auc: 0.6834 - f1_score: 0.0156 - loss: 3.8239 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0547 - val_auc: 0.5228 - val_f1_score: 0.0369 - val_loss: 3.8990 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 132ms/step - accuracy: 0.0207 - auc: 0.6827 - f1_score: 0.0040 - loss: 3.7899 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5285 - val_f1_score: 7.8457e-04 - val_loss: 3.9488 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 133ms/step - accuracy: 0.0743 - auc: 0.7682 - f1_score: 0.0106 - loss: 3.5535 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0477 - val_auc: 0.5504 - val_f1_score: 0.0344 - val_loss: 3.8698 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 134ms/step - accuracy: 0.0313 - auc: 0.7093 - f1_score: 0.0094 - loss: 3.7596 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0540 - val_auc: 0.6035 - val_f1_score: 0.0231 - val_loss: 3.8259 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 134ms/step - accuracy: 0.0224 - auc: 0.7091 - f1_score: 0.0080 - loss: 3.7169 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0504 - val_auc: 0.5554 - val_f1_score: 0.0220 - val_loss: 4.1733 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0448 - auc: 0.6998 - f1_score: 0.0172 - loss: 3.7257 - precision: 0.1734 - recall: 0.0010 - val_accuracy: 0.0750 - val_auc: 0.6162 - val_f1_score: 0.0303 - val_loss: 3.7825 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 134ms/step - accuracy: 0.0312 - auc: 0.7524 - f1_score: 0.0133 - loss: 3.5795 - precision: 0.3093 - recall: 0.0044 - val_accuracy: 0.0610 - val_auc: 0.6073 - val_f1_score: 0.0215 - val_loss: 3.8264 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0514 - auc: 0.7658 - f1_score: 0.0224 - loss: 3.4785 - precision: 0.5067 - recall: 0.0042 - val_accuracy: 0.0577 - val_auc: 0.6191 - val_f1_score: 0.0197 - val_loss: 3.8606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 134ms/step - accuracy: 0.0788 - auc: 0.7331 - f1_score: 0.0362 - loss: 3.4940 - precision: 0.5036 - recall: 0.0075 - val_accuracy: 0.0544 - val_auc: 0.6056 - val_f1_score: 0.0265 - val_loss: 4.1503 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 134ms/step - accuracy: 0.0564 - auc: 0.7252 - f1_score: 0.0278 - loss: 3.5376 - precision: 0.3318 - recall: 0.0057 - val_accuracy: 0.0664 - val_auc: 0.6259 - val_f1_score: 0.0423 - val_loss: 4.0867 - val_precision: 0.3810 - val_recall: 0.0027\n",
      "Epoch 13/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.0678 - auc: 0.7495 - f1_score: 0.0365 - loss: 3.4661 - precision: 0.4697 - recall: 0.0086 - val_accuracy: 0.0874 - val_auc: 0.6608 - val_f1_score: 0.0576 - val_loss: 3.7812 - val_precision: 0.4211 - val_recall: 0.0053\n",
      "Epoch 14/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 143ms/step - accuracy: 0.0906 - auc: 0.7495 - f1_score: 0.0466 - loss: 3.4409 - precision: 0.3690 - recall: 0.0107 - val_accuracy: 0.0970 - val_auc: 0.6418 - val_f1_score: 0.0610 - val_loss: 4.1356 - val_precision: 0.2766 - val_recall: 0.0043\n",
      "Epoch 15/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 134ms/step - accuracy: 0.0988 - auc: 0.7590 - f1_score: 0.0505 - loss: 3.3822 - precision: 0.5803 - recall: 0.0189 - val_accuracy: 0.0957 - val_auc: 0.6675 - val_f1_score: 0.0700 - val_loss: 3.8446 - val_precision: 0.3725 - val_recall: 0.0063\n",
      "Epoch 16/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.1171 - auc: 0.7689 - f1_score: 0.0588 - loss: 3.3487 - precision: 0.5876 - recall: 0.0284 - val_accuracy: 0.1100 - val_auc: 0.6658 - val_f1_score: 0.0796 - val_loss: 3.9105 - val_precision: 0.4211 - val_recall: 0.0107\n",
      "Epoch 17/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.0977 - auc: 0.7841 - f1_score: 0.0486 - loss: 3.2999 - precision: 0.5355 - recall: 0.0330 - val_accuracy: 0.1164 - val_auc: 0.6908 - val_f1_score: 0.0854 - val_loss: 3.7485 - val_precision: 0.5476 - val_recall: 0.0153\n",
      "Epoch 18/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 135ms/step - accuracy: 0.1130 - auc: 0.8017 - f1_score: 0.0614 - loss: 3.2263 - precision: 0.5975 - recall: 0.0380 - val_accuracy: 0.1464 - val_auc: 0.6863 - val_f1_score: 0.1042 - val_loss: 3.8164 - val_precision: 0.6602 - val_recall: 0.0227\n",
      "Epoch 19/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.1303 - auc: 0.8204 - f1_score: 0.0724 - loss: 3.1371 - precision: 0.5850 - recall: 0.0443 - val_accuracy: 0.1607 - val_auc: 0.7156 - val_f1_score: 0.1175 - val_loss: 3.5948 - val_precision: 0.7946 - val_recall: 0.0297\n",
      "Epoch 20/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 135ms/step - accuracy: 0.1258 - auc: 0.8289 - f1_score: 0.0695 - loss: 3.1205 - precision: 0.5547 - recall: 0.0444 - val_accuracy: 0.1641 - val_auc: 0.7186 - val_f1_score: 0.1210 - val_loss: 3.5745 - val_precision: 0.8271 - val_recall: 0.0367\n",
      "Epoch 21/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.1513 - auc: 0.8523 - f1_score: 0.0780 - loss: 2.9845 - precision: 0.5492 - recall: 0.0632 - val_accuracy: 0.1767 - val_auc: 0.7182 - val_f1_score: 0.1305 - val_loss: 3.6079 - val_precision: 0.8141 - val_recall: 0.0423\n",
      "Epoch 22/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.1455 - auc: 0.8401 - f1_score: 0.0794 - loss: 3.0278 - precision: 0.6227 - recall: 0.0596 - val_accuracy: 0.1947 - val_auc: 0.7775 - val_f1_score: 0.1541 - val_loss: 3.2257 - val_precision: 0.8917 - val_recall: 0.0467\n",
      "Epoch 23/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.1583 - auc: 0.8397 - f1_score: 0.0885 - loss: 3.0308 - precision: 0.6097 - recall: 0.0530 - val_accuracy: 0.2111 - val_auc: 0.7893 - val_f1_score: 0.1645 - val_loss: 3.1720 - val_precision: 0.8868 - val_recall: 0.0470\n",
      "Epoch 24/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.1589 - auc: 0.8446 - f1_score: 0.0928 - loss: 3.0022 - precision: 0.5585 - recall: 0.0561 - val_accuracy: 0.2241 - val_auc: 0.7977 - val_f1_score: 0.1714 - val_loss: 3.1185 - val_precision: 0.7914 - val_recall: 0.0493\n",
      "Epoch 25/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.1860 - auc: 0.8483 - f1_score: 0.0989 - loss: 2.9414 - precision: 0.6545 - recall: 0.0677 - val_accuracy: 0.1991 - val_auc: 0.7433 - val_f1_score: 0.1392 - val_loss: 3.5452 - val_precision: 0.6356 - val_recall: 0.0500\n",
      "Epoch 26/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.1630 - auc: 0.8506 - f1_score: 0.0884 - loss: 2.9318 - precision: 0.5657 - recall: 0.0653 - val_accuracy: 0.1984 - val_auc: 0.7459 - val_f1_score: 0.1400 - val_loss: 3.5819 - val_precision: 0.5709 - val_recall: 0.0510\n",
      "Epoch 27/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.1953 - auc: 0.8534 - f1_score: 0.1001 - loss: 2.9126 - precision: 0.5927 - recall: 0.0713 - val_accuracy: 0.2101 - val_auc: 0.7979 - val_f1_score: 0.1579 - val_loss: 3.1604 - val_precision: 0.6855 - val_recall: 0.0647\n",
      "Epoch 28/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.2220 - auc: 0.8589 - f1_score: 0.1058 - loss: 2.8321 - precision: 0.5865 - recall: 0.0737 - val_accuracy: 0.2211 - val_auc: 0.8055 - val_f1_score: 0.1714 - val_loss: 3.1187 - val_precision: 0.6227 - val_recall: 0.0677\n",
      "Epoch 29/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.2443 - auc: 0.8589 - f1_score: 0.1151 - loss: 2.7997 - precision: 0.7105 - recall: 0.0891 - val_accuracy: 0.2331 - val_auc: 0.7934 - val_f1_score: 0.1707 - val_loss: 3.2019 - val_precision: 0.6458 - val_recall: 0.0724\n",
      "Epoch 30/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.2492 - auc: 0.8717 - f1_score: 0.1177 - loss: 2.7202 - precision: 0.6754 - recall: 0.1075 - val_accuracy: 0.2331 - val_auc: 0.8286 - val_f1_score: 0.1815 - val_loss: 2.9818 - val_precision: 0.6031 - val_recall: 0.0780\n",
      "Epoch 31/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.2642 - auc: 0.8893 - f1_score: 0.1219 - loss: 2.6104 - precision: 0.6802 - recall: 0.1195 - val_accuracy: 0.2477 - val_auc: 0.8258 - val_f1_score: 0.1929 - val_loss: 2.9725 - val_precision: 0.7335 - val_recall: 0.0927\n",
      "Epoch 32/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.2594 - auc: 0.8789 - f1_score: 0.1269 - loss: 2.6649 - precision: 0.6625 - recall: 0.1073 - val_accuracy: 0.2648 - val_auc: 0.8482 - val_f1_score: 0.2104 - val_loss: 2.8344 - val_precision: 0.7289 - val_recall: 0.0950\n",
      "Epoch 33/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.2816 - auc: 0.8875 - f1_score: 0.1363 - loss: 2.5726 - precision: 0.7629 - recall: 0.1315 - val_accuracy: 0.2621 - val_auc: 0.8596 - val_f1_score: 0.2089 - val_loss: 2.7792 - val_precision: 0.6778 - val_recall: 0.0877\n",
      "Epoch 34/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.2799 - auc: 0.8843 - f1_score: 0.1319 - loss: 2.6150 - precision: 0.7025 - recall: 0.1167 - val_accuracy: 0.2784 - val_auc: 0.8568 - val_f1_score: 0.2210 - val_loss: 2.7759 - val_precision: 0.6893 - val_recall: 0.0947\n",
      "Epoch 35/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.2955 - auc: 0.8900 - f1_score: 0.1384 - loss: 2.5693 - precision: 0.7056 - recall: 0.1229 - val_accuracy: 0.2928 - val_auc: 0.8690 - val_f1_score: 0.2384 - val_loss: 2.7169 - val_precision: 0.7166 - val_recall: 0.1037\n",
      "Epoch 36/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3025 - auc: 0.8935 - f1_score: 0.1419 - loss: 2.5308 - precision: 0.7579 - recall: 0.1371 - val_accuracy: 0.3068 - val_auc: 0.8758 - val_f1_score: 0.2527 - val_loss: 2.6649 - val_precision: 0.7218 - val_recall: 0.1150\n",
      "Epoch 37/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3096 - auc: 0.8962 - f1_score: 0.1450 - loss: 2.5188 - precision: 0.7555 - recall: 0.1393 - val_accuracy: 0.3041 - val_auc: 0.8720 - val_f1_score: 0.2498 - val_loss: 2.6813 - val_precision: 0.7269 - val_recall: 0.1127\n",
      "Epoch 38/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3218 - auc: 0.8981 - f1_score: 0.1464 - loss: 2.4796 - precision: 0.7579 - recall: 0.1483 - val_accuracy: 0.3274 - val_auc: 0.8860 - val_f1_score: 0.2752 - val_loss: 2.5900 - val_precision: 0.7577 - val_recall: 0.1230\n",
      "Epoch 39/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3140 - auc: 0.8985 - f1_score: 0.1464 - loss: 2.4930 - precision: 0.7443 - recall: 0.1379 - val_accuracy: 0.3351 - val_auc: 0.8883 - val_f1_score: 0.2867 - val_loss: 2.5669 - val_precision: 0.7495 - val_recall: 0.1287\n",
      "Epoch 40/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 137ms/step - accuracy: 0.3209 - auc: 0.9035 - f1_score: 0.1540 - loss: 2.4357 - precision: 0.7505 - recall: 0.1574 - val_accuracy: 0.3334 - val_auc: 0.8851 - val_f1_score: 0.2827 - val_loss: 2.5831 - val_precision: 0.7454 - val_recall: 0.1357\n",
      "Epoch 41/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3300 - auc: 0.9062 - f1_score: 0.1598 - loss: 2.4284 - precision: 0.7417 - recall: 0.1592 - val_accuracy: 0.3418 - val_auc: 0.8907 - val_f1_score: 0.2931 - val_loss: 2.5300 - val_precision: 0.7465 - val_recall: 0.1404\n",
      "Epoch 42/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3400 - auc: 0.9058 - f1_score: 0.1630 - loss: 2.4051 - precision: 0.7474 - recall: 0.1553 - val_accuracy: 0.3471 - val_auc: 0.8907 - val_f1_score: 0.3008 - val_loss: 2.5268 - val_precision: 0.7408 - val_recall: 0.1477\n",
      "Epoch 43/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.3339 - auc: 0.9100 - f1_score: 0.1652 - loss: 2.3655 - precision: 0.7846 - recall: 0.1759 - val_accuracy: 0.3608 - val_auc: 0.9062 - val_f1_score: 0.3162 - val_loss: 2.3987 - val_precision: 0.7826 - val_recall: 0.1621\n",
      "Epoch 44/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3524 - auc: 0.9150 - f1_score: 0.1681 - loss: 2.3045 - precision: 0.7914 - recall: 0.1912 - val_accuracy: 0.3391 - val_auc: 0.8925 - val_f1_score: 0.2932 - val_loss: 2.4971 - val_precision: 0.7363 - val_recall: 0.1657\n",
      "Epoch 45/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.3469 - auc: 0.9104 - f1_score: 0.1696 - loss: 2.3445 - precision: 0.7456 - recall: 0.1893 - val_accuracy: 0.3424 - val_auc: 0.8941 - val_f1_score: 0.2985 - val_loss: 2.4854 - val_precision: 0.7405 - val_recall: 0.1694\n",
      "Epoch 46/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 144ms/step - accuracy: 0.3577 - auc: 0.9134 - f1_score: 0.1795 - loss: 2.3075 - precision: 0.7654 - recall: 0.1894 - val_accuracy: 0.3414 - val_auc: 0.8986 - val_f1_score: 0.2982 - val_loss: 2.4430 - val_precision: 0.7532 - val_recall: 0.1771\n",
      "Epoch 47/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.3620 - auc: 0.9138 - f1_score: 0.1800 - loss: 2.2904 - precision: 0.7698 - recall: 0.1988 - val_accuracy: 0.3354 - val_auc: 0.8956 - val_f1_score: 0.2905 - val_loss: 2.4652 - val_precision: 0.7063 - val_recall: 0.1781\n",
      "Epoch 48/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3677 - auc: 0.9171 - f1_score: 0.1864 - loss: 2.2656 - precision: 0.7840 - recall: 0.2003 - val_accuracy: 0.3491 - val_auc: 0.9027 - val_f1_score: 0.3073 - val_loss: 2.4053 - val_precision: 0.7341 - val_recall: 0.1851\n",
      "Epoch 49/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3743 - auc: 0.9197 - f1_score: 0.1907 - loss: 2.2334 - precision: 0.7698 - recall: 0.2033 - val_accuracy: 0.3324 - val_auc: 0.8925 - val_f1_score: 0.2873 - val_loss: 2.4890 - val_precision: 0.7045 - val_recall: 0.1861\n",
      "Epoch 50/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3831 - auc: 0.9202 - f1_score: 0.1943 - loss: 2.2161 - precision: 0.7755 - recall: 0.2108 - val_accuracy: 0.3371 - val_auc: 0.8986 - val_f1_score: 0.2942 - val_loss: 2.4270 - val_precision: 0.7156 - val_recall: 0.1871\n",
      "Epoch 51/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3822 - auc: 0.9201 - f1_score: 0.1973 - loss: 2.2153 - precision: 0.7687 - recall: 0.2118 - val_accuracy: 0.3258 - val_auc: 0.8938 - val_f1_score: 0.2829 - val_loss: 2.4807 - val_precision: 0.6889 - val_recall: 0.1794\n",
      "Epoch 52/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3599 - auc: 0.9192 - f1_score: 0.1882 - loss: 2.2363 - precision: 0.7615 - recall: 0.2190 - val_accuracy: 0.3211 - val_auc: 0.8843 - val_f1_score: 0.2672 - val_loss: 2.5703 - val_precision: 0.6391 - val_recall: 0.1907\n",
      "Epoch 53/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.3815 - auc: 0.9210 - f1_score: 0.1981 - loss: 2.1987 - precision: 0.7685 - recall: 0.2288 - val_accuracy: 0.3371 - val_auc: 0.8860 - val_f1_score: 0.2813 - val_loss: 2.5433 - val_precision: 0.6385 - val_recall: 0.1891\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 96ms/step - accuracy: 0.3552 - auc: 0.8963 - f1_score: 0.1795 - loss: 2.4447 - precision: 0.7849 - recall: 0.1867\n",
      "VGG16 Final Accuracy: 0.3608\n",
      "Training VGG19\n",
      "Epoch 1/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 175ms/step - accuracy: 0.0439 - auc: 0.5405 - f1_score: 0.0063 - loss: 4.4566 - precision: 0.0281 - recall: 0.0061 - val_accuracy: 0.0200 - val_auc: 0.5076 - val_f1_score: 7.8585e-04 - val_loss: 3.9168 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0207 - auc: 0.6315 - f1_score: 0.0033 - loss: 3.8867 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5106 - val_f1_score: 7.8457e-04 - val_loss: 3.9581 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0403 - auc: 0.5252 - f1_score: 0.0062 - loss: 3.9584 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0407 - val_auc: 0.5245 - val_f1_score: 0.0285 - val_loss: 3.9049 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 159ms/step - accuracy: 0.0689 - auc: 0.7192 - f1_score: 0.0089 - loss: 3.7397 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0267 - val_auc: 0.5113 - val_f1_score: 0.0108 - val_loss: 4.1400 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0308 - auc: 0.6973 - f1_score: 0.0057 - loss: 3.7862 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0437 - val_auc: 0.5413 - val_f1_score: 0.0219 - val_loss: 3.8993 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0192 - auc: 0.6274 - f1_score: 0.0052 - loss: 3.8629 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0243 - val_auc: 0.5207 - val_f1_score: 0.0048 - val_loss: 4.0866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.0224 - auc: 0.6724 - f1_score: 0.0057 - loss: 3.7551 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0260 - val_auc: 0.5285 - val_f1_score: 0.0058 - val_loss: 3.9544 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0184 - auc: 0.6445 - f1_score: 0.0061 - loss: 3.8789 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0360 - val_auc: 0.5361 - val_f1_score: 0.0089 - val_loss: 3.8573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.0385 - auc: 0.7257 - f1_score: 0.0127 - loss: 3.7479 - precision: 0.2984 - recall: 1.4853e-04 - val_accuracy: 0.0397 - val_auc: 0.5444 - val_f1_score: 0.0130 - val_loss: 3.8385 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.0286 - auc: 0.6767 - f1_score: 0.0105 - loss: 3.7712 - precision: 0.4853 - recall: 0.0025 - val_accuracy: 0.0477 - val_auc: 0.5570 - val_f1_score: 0.0208 - val_loss: 3.8338 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 158ms/step - accuracy: 0.0207 - auc: 0.6299 - f1_score: 0.0060 - loss: 3.8153 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0397 - val_auc: 0.5438 - val_f1_score: 0.0132 - val_loss: 3.8957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0889 - auc: 0.7163 - f1_score: 0.0174 - loss: 3.6377 - precision: 0.4955 - recall: 0.0089 - val_accuracy: 0.0443 - val_auc: 0.5339 - val_f1_score: 0.0197 - val_loss: 4.5767 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0371 - auc: 0.7115 - f1_score: 0.0118 - loss: 3.5398 - precision: 0.1956 - recall: 0.0015 - val_accuracy: 0.0390 - val_auc: 0.5687 - val_f1_score: 0.0103 - val_loss: 3.8024 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.0252 - auc: 0.5827 - f1_score: 0.0119 - loss: 3.7900 - precision: 0.2019 - recall: 2.9706e-04 - val_accuracy: 0.0243 - val_auc: 0.5633 - val_f1_score: 0.0103 - val_loss: 3.8015 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 159ms/step - accuracy: 0.0549 - auc: 0.6793 - f1_score: 0.0148 - loss: 3.6333 - precision: 0.4020 - recall: 0.0048 - val_accuracy: 0.0443 - val_auc: 0.5745 - val_f1_score: 0.0119 - val_loss: 3.7878 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0244 - auc: 0.5521 - f1_score: 0.0100 - loss: 3.7723 - precision: 0.1342 - recall: 4.4195e-04 - val_accuracy: 0.0410 - val_auc: 0.5891 - val_f1_score: 0.0121 - val_loss: 3.7781 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0298 - auc: 0.5614 - f1_score: 0.0121 - loss: 3.7364 - precision: 0.2579 - recall: 0.0026 - val_accuracy: 0.0490 - val_auc: 0.5939 - val_f1_score: 0.0107 - val_loss: 3.7839 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0528 - auc: 0.5892 - f1_score: 0.0156 - loss: 3.7846 - precision: 0.2156 - recall: 0.0025 - val_accuracy: 0.0460 - val_auc: 0.6109 - val_f1_score: 0.0154 - val_loss: 3.7492 - val_precision: 1.0000 - val_recall: 3.3344e-04\n",
      "Epoch 19/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0449 - auc: 0.6217 - f1_score: 0.0158 - loss: 3.7122 - precision: 0.3326 - recall: 0.0045 - val_accuracy: 0.0490 - val_auc: 0.5742 - val_f1_score: 0.0226 - val_loss: 4.0089 - val_precision: 1.0000 - val_recall: 6.6689e-04\n",
      "Epoch 20/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0620 - auc: 0.5914 - f1_score: 0.0178 - loss: 3.7866 - precision: 0.2396 - recall: 0.0021 - val_accuracy: 0.0594 - val_auc: 0.6268 - val_f1_score: 0.0315 - val_loss: 3.7284 - val_precision: 1.0000 - val_recall: 0.0013\n",
      "Epoch 21/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.0444 - auc: 0.7129 - f1_score: 0.0165 - loss: 3.5904 - precision: 0.3241 - recall: 0.0049 - val_accuracy: 0.0557 - val_auc: 0.6281 - val_f1_score: 0.0296 - val_loss: 3.7621 - val_precision: 1.0000 - val_recall: 0.0017\n",
      "Epoch 22/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.0707 - auc: 0.6650 - f1_score: 0.0217 - loss: 3.6987 - precision: 0.3196 - recall: 0.0016 - val_accuracy: 0.0567 - val_auc: 0.6144 - val_f1_score: 0.0348 - val_loss: 3.7393 - val_precision: 1.0000 - val_recall: 0.0020\n",
      "Epoch 23/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.0826 - auc: 0.7522 - f1_score: 0.0281 - loss: 3.4597 - precision: 0.6087 - recall: 0.0247 - val_accuracy: 0.0744 - val_auc: 0.6128 - val_f1_score: 0.0283 - val_loss: 3.8436 - val_precision: 1.0000 - val_recall: 0.0113\n",
      "Epoch 24/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.0835 - auc: 0.6894 - f1_score: 0.0276 - loss: 3.6294 - precision: 0.4811 - recall: 0.0039 - val_accuracy: 0.0710 - val_auc: 0.5685 - val_f1_score: 0.0336 - val_loss: 4.3992 - val_precision: 0.9000 - val_recall: 0.0120\n",
      "Epoch 25/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 158ms/step - accuracy: 0.0888 - auc: 0.6913 - f1_score: 0.0348 - loss: 3.6286 - precision: 0.4523 - recall: 0.0061 - val_accuracy: 0.0854 - val_auc: 0.6129 - val_f1_score: 0.0394 - val_loss: 3.8547 - val_precision: 1.0000 - val_recall: 0.0113\n",
      "Epoch 26/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 159ms/step - accuracy: 0.0891 - auc: 0.6589 - f1_score: 0.0296 - loss: 3.6393 - precision: 0.6410 - recall: 0.0049 - val_accuracy: 0.0684 - val_auc: 0.5628 - val_f1_score: 0.0323 - val_loss: 4.9298 - val_precision: 0.8000 - val_recall: 0.0067\n",
      "Epoch 27/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.0711 - auc: 0.6857 - f1_score: 0.0277 - loss: 3.6521 - precision: 0.4942 - recall: 0.0226 - val_accuracy: 0.0807 - val_auc: 0.6149 - val_f1_score: 0.0364 - val_loss: 3.8772 - val_precision: 0.8889 - val_recall: 0.0187\n",
      "Epoch 28/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0894 - auc: 0.6955 - f1_score: 0.0330 - loss: 3.5651 - precision: 0.5927 - recall: 0.0193 - val_accuracy: 0.0987 - val_auc: 0.5950 - val_f1_score: 0.0436 - val_loss: 4.2306 - val_precision: 0.6053 - val_recall: 0.0153\n",
      "Epoch 29/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.0775 - auc: 0.6780 - f1_score: 0.0318 - loss: 3.6449 - precision: 0.5608 - recall: 0.0108 - val_accuracy: 0.0927 - val_auc: 0.5936 - val_f1_score: 0.0462 - val_loss: 4.2679 - val_precision: 0.5000 - val_recall: 0.0113\n",
      "Epoch 30/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 162ms/step - accuracy: 0.0816 - auc: 0.6925 - f1_score: 0.0310 - loss: 3.6092 - precision: 0.5778 - recall: 0.0123 - val_accuracy: 0.1074 - val_auc: 0.6713 - val_f1_score: 0.0578 - val_loss: 3.6742 - val_precision: 0.7273 - val_recall: 0.0240\n",
      "Epoch 31/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 158ms/step - accuracy: 0.0817 - auc: 0.7128 - f1_score: 0.0327 - loss: 3.5208 - precision: 0.6359 - recall: 0.0154 - val_accuracy: 0.0880 - val_auc: 0.5924 - val_f1_score: 0.0440 - val_loss: 4.6437 - val_precision: 0.3968 - val_recall: 0.0167\n",
      "Epoch 32/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0826 - auc: 0.7223 - f1_score: 0.0324 - loss: 3.5241 - precision: 0.6625 - recall: 0.0161 - val_accuracy: 0.1094 - val_auc: 0.6126 - val_f1_score: 0.0696 - val_loss: 4.2064 - val_precision: 0.4530 - val_recall: 0.0177\n",
      "Epoch 33/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.0764 - auc: 0.7566 - f1_score: 0.0360 - loss: 3.4159 - precision: 0.5824 - recall: 0.0245 - val_accuracy: 0.1170 - val_auc: 0.6418 - val_f1_score: 0.0656 - val_loss: 3.9399 - val_precision: 0.5586 - val_recall: 0.0270\n",
      "Epoch 34/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.0823 - auc: 0.7359 - f1_score: 0.0374 - loss: 3.4717 - precision: 0.6523 - recall: 0.0289 - val_accuracy: 0.1304 - val_auc: 0.6926 - val_f1_score: 0.0732 - val_loss: 3.5637 - val_precision: 0.6774 - val_recall: 0.0280\n",
      "Epoch 35/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.1132 - auc: 0.7877 - f1_score: 0.0508 - loss: 3.2665 - precision: 0.6331 - recall: 0.0457 - val_accuracy: 0.1287 - val_auc: 0.6512 - val_f1_score: 0.0837 - val_loss: 3.8511 - val_precision: 0.5259 - val_recall: 0.0237\n",
      "Epoch 36/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 162ms/step - accuracy: 0.0999 - auc: 0.7540 - f1_score: 0.0438 - loss: 3.3917 - precision: 0.7228 - recall: 0.0216 - val_accuracy: 0.1417 - val_auc: 0.7005 - val_f1_score: 0.0806 - val_loss: 3.5500 - val_precision: 0.6645 - val_recall: 0.0343\n",
      "Epoch 37/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 162ms/step - accuracy: 0.1344 - auc: 0.7706 - f1_score: 0.0567 - loss: 3.2979 - precision: 0.6959 - recall: 0.0490 - val_accuracy: 0.1427 - val_auc: 0.7082 - val_f1_score: 0.0855 - val_loss: 3.5387 - val_precision: 0.6402 - val_recall: 0.0350\n",
      "Epoch 38/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.1751 - auc: 0.8075 - f1_score: 0.0583 - loss: 3.1793 - precision: 0.6426 - recall: 0.0498 - val_accuracy: 0.1511 - val_auc: 0.7231 - val_f1_score: 0.0915 - val_loss: 3.4736 - val_precision: 0.6438 - val_recall: 0.0343\n",
      "Epoch 39/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.1113 - auc: 0.7546 - f1_score: 0.0535 - loss: 3.3926 - precision: 0.6627 - recall: 0.0266 - val_accuracy: 0.1364 - val_auc: 0.6988 - val_f1_score: 0.0801 - val_loss: 3.5930 - val_precision: 0.6141 - val_recall: 0.0377\n",
      "Epoch 40/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.1152 - auc: 0.7544 - f1_score: 0.0523 - loss: 3.3752 - precision: 0.6515 - recall: 0.0241 - val_accuracy: 0.1604 - val_auc: 0.7474 - val_f1_score: 0.0978 - val_loss: 3.3725 - val_precision: 0.7039 - val_recall: 0.0357\n",
      "Epoch 41/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 208ms/step - accuracy: 0.1450 - auc: 0.7784 - f1_score: 0.0662 - loss: 3.2594 - precision: 0.7188 - recall: 0.0435 - val_accuracy: 0.1517 - val_auc: 0.7540 - val_f1_score: 0.0910 - val_loss: 3.3733 - val_precision: 0.6933 - val_recall: 0.0377\n",
      "Epoch 42/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 158ms/step - accuracy: 0.1340 - auc: 0.7524 - f1_score: 0.0593 - loss: 3.3529 - precision: 0.7000 - recall: 0.0309 - val_accuracy: 0.1674 - val_auc: 0.7578 - val_f1_score: 0.1060 - val_loss: 3.3476 - val_precision: 0.6800 - val_recall: 0.0397\n",
      "Epoch 43/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.1340 - auc: 0.7711 - f1_score: 0.0633 - loss: 3.2980 - precision: 0.7067 - recall: 0.0354 - val_accuracy: 0.1671 - val_auc: 0.7685 - val_f1_score: 0.1111 - val_loss: 3.3130 - val_precision: 0.7241 - val_recall: 0.0420\n",
      "Epoch 44/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.1450 - auc: 0.7647 - f1_score: 0.0640 - loss: 3.3118 - precision: 0.6819 - recall: 0.0354 - val_accuracy: 0.1767 - val_auc: 0.7752 - val_f1_score: 0.1167 - val_loss: 3.2882 - val_precision: 0.7204 - val_recall: 0.0447\n",
      "Epoch 45/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.1462 - auc: 0.7858 - f1_score: 0.0693 - loss: 3.2464 - precision: 0.6613 - recall: 0.0434 - val_accuracy: 0.1731 - val_auc: 0.7791 - val_f1_score: 0.1154 - val_loss: 3.2781 - val_precision: 0.7278 - val_recall: 0.0410\n",
      "Epoch 46/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.1335 - auc: 0.7767 - f1_score: 0.0646 - loss: 3.2835 - precision: 0.6974 - recall: 0.0383 - val_accuracy: 0.1814 - val_auc: 0.7836 - val_f1_score: 0.1227 - val_loss: 3.2496 - val_precision: 0.7254 - val_recall: 0.0467\n",
      "Epoch 47/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 162ms/step - accuracy: 0.1629 - auc: 0.8027 - f1_score: 0.0755 - loss: 3.1822 - precision: 0.6732 - recall: 0.0449 - val_accuracy: 0.1847 - val_auc: 0.7851 - val_f1_score: 0.1273 - val_loss: 3.2461 - val_precision: 0.7347 - val_recall: 0.0480\n",
      "Epoch 48/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.1678 - auc: 0.7828 - f1_score: 0.0746 - loss: 3.2468 - precision: 0.6358 - recall: 0.0355 - val_accuracy: 0.1907 - val_auc: 0.7811 - val_f1_score: 0.1304 - val_loss: 3.2543 - val_precision: 0.7308 - val_recall: 0.0507\n",
      "Epoch 49/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.1992 - auc: 0.8268 - f1_score: 0.0833 - loss: 3.0584 - precision: 0.7080 - recall: 0.0562 - val_accuracy: 0.1764 - val_auc: 0.7728 - val_f1_score: 0.1251 - val_loss: 3.2859 - val_precision: 0.6991 - val_recall: 0.0527\n",
      "Epoch 50/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.1858 - auc: 0.8015 - f1_score: 0.0839 - loss: 3.1453 - precision: 0.7056 - recall: 0.0529 - val_accuracy: 0.1767 - val_auc: 0.7780 - val_f1_score: 0.1255 - val_loss: 3.2647 - val_precision: 0.7432 - val_recall: 0.0550\n",
      "Epoch 51/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.1961 - auc: 0.8063 - f1_score: 0.0802 - loss: 3.1222 - precision: 0.6679 - recall: 0.0510 - val_accuracy: 0.1801 - val_auc: 0.7853 - val_f1_score: 0.1297 - val_loss: 3.2312 - val_precision: 0.7339 - val_recall: 0.0570\n",
      "Epoch 52/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.2216 - auc: 0.8185 - f1_score: 0.0929 - loss: 3.0620 - precision: 0.7366 - recall: 0.0602 - val_accuracy: 0.1711 - val_auc: 0.7649 - val_f1_score: 0.1233 - val_loss: 3.3154 - val_precision: 0.7088 - val_recall: 0.0617\n",
      "Epoch 53/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.2036 - auc: 0.8109 - f1_score: 0.0905 - loss: 3.1001 - precision: 0.6818 - recall: 0.0544 - val_accuracy: 0.1711 - val_auc: 0.7624 - val_f1_score: 0.1263 - val_loss: 3.3232 - val_precision: 0.7349 - val_recall: 0.0610\n",
      "Epoch 54/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.2142 - auc: 0.8235 - f1_score: 0.0898 - loss: 3.0317 - precision: 0.7050 - recall: 0.0611 - val_accuracy: 0.1691 - val_auc: 0.7562 - val_f1_score: 0.1237 - val_loss: 3.3594 - val_precision: 0.7410 - val_recall: 0.0620\n",
      "Epoch 55/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.2062 - auc: 0.8185 - f1_score: 0.0907 - loss: 3.0486 - precision: 0.7266 - recall: 0.0631 - val_accuracy: 0.1747 - val_auc: 0.7586 - val_f1_score: 0.1304 - val_loss: 3.3465 - val_precision: 0.7451 - val_recall: 0.0634\n",
      "Epoch 56/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.2186 - auc: 0.8304 - f1_score: 0.0904 - loss: 2.9987 - precision: 0.6848 - recall: 0.0632 - val_accuracy: 0.1714 - val_auc: 0.7530 - val_f1_score: 0.1273 - val_loss: 3.3849 - val_precision: 0.7383 - val_recall: 0.0630\n",
      "Epoch 57/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.1984 - auc: 0.8237 - f1_score: 0.0868 - loss: 3.0369 - precision: 0.7116 - recall: 0.0614 - val_accuracy: 0.1771 - val_auc: 0.7554 - val_f1_score: 0.1349 - val_loss: 3.3795 - val_precision: 0.7874 - val_recall: 0.0667\n",
      "Epoch 58/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.2249 - auc: 0.8517 - f1_score: 0.1000 - loss: 2.8910 - precision: 0.6373 - recall: 0.0676 - val_accuracy: 0.1884 - val_auc: 0.7820 - val_f1_score: 0.1487 - val_loss: 3.2173 - val_precision: 0.7549 - val_recall: 0.0647\n",
      "Epoch 59/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 163ms/step - accuracy: 0.2146 - auc: 0.8628 - f1_score: 0.0971 - loss: 2.8390 - precision: 0.6334 - recall: 0.0681 - val_accuracy: 0.1961 - val_auc: 0.7879 - val_f1_score: 0.1553 - val_loss: 3.1836 - val_precision: 0.7638 - val_recall: 0.0690\n",
      "Epoch 60/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.2163 - auc: 0.8489 - f1_score: 0.0955 - loss: 2.8937 - precision: 0.7271 - recall: 0.0821 - val_accuracy: 0.1951 - val_auc: 0.7908 - val_f1_score: 0.1574 - val_loss: 3.1711 - val_precision: 0.7634 - val_recall: 0.0710\n",
      "Epoch 61/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.2108 - auc: 0.8512 - f1_score: 0.0936 - loss: 2.8919 - precision: 0.7078 - recall: 0.0825 - val_accuracy: 0.2121 - val_auc: 0.8183 - val_f1_score: 0.1674 - val_loss: 3.0371 - val_precision: 0.7643 - val_recall: 0.0714\n",
      "Epoch 62/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.2106 - auc: 0.8581 - f1_score: 0.0932 - loss: 2.8508 - precision: 0.7471 - recall: 0.0937 - val_accuracy: 0.2187 - val_auc: 0.8329 - val_f1_score: 0.1755 - val_loss: 2.9725 - val_precision: 0.7818 - val_recall: 0.0717\n",
      "Epoch 63/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.2186 - auc: 0.8567 - f1_score: 0.0989 - loss: 2.8395 - precision: 0.7217 - recall: 0.0930 - val_accuracy: 0.2274 - val_auc: 0.8489 - val_f1_score: 0.1859 - val_loss: 2.9047 - val_precision: 0.8229 - val_recall: 0.0744\n",
      "Epoch 64/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.2247 - auc: 0.8597 - f1_score: 0.1032 - loss: 2.8155 - precision: 0.7473 - recall: 0.1107 - val_accuracy: 0.2391 - val_auc: 0.8527 - val_f1_score: 0.1981 - val_loss: 2.8797 - val_precision: 0.8425 - val_recall: 0.0820\n",
      "Epoch 65/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.2284 - auc: 0.8581 - f1_score: 0.1086 - loss: 2.8173 - precision: 0.7624 - recall: 0.1117 - val_accuracy: 0.2457 - val_auc: 0.8626 - val_f1_score: 0.2112 - val_loss: 2.8498 - val_precision: 0.8551 - val_recall: 0.0787\n",
      "Epoch 66/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 160ms/step - accuracy: 0.2257 - auc: 0.8578 - f1_score: 0.1069 - loss: 2.8069 - precision: 0.7757 - recall: 0.1150 - val_accuracy: 0.2434 - val_auc: 0.8632 - val_f1_score: 0.2128 - val_loss: 2.8481 - val_precision: 0.8291 - val_recall: 0.0760\n",
      "Epoch 67/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.2319 - auc: 0.8584 - f1_score: 0.1066 - loss: 2.7906 - precision: 0.7920 - recall: 0.1221 - val_accuracy: 0.2471 - val_auc: 0.8660 - val_f1_score: 0.2154 - val_loss: 2.8272 - val_precision: 0.8432 - val_recall: 0.0807\n",
      "Epoch 68/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.2267 - auc: 0.8581 - f1_score: 0.1109 - loss: 2.8038 - precision: 0.7700 - recall: 0.1225 - val_accuracy: 0.2518 - val_auc: 0.8682 - val_f1_score: 0.2206 - val_loss: 2.8091 - val_precision: 0.8444 - val_recall: 0.0850\n",
      "Epoch 69/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.2300 - auc: 0.8648 - f1_score: 0.1117 - loss: 2.7635 - precision: 0.7639 - recall: 0.1263 - val_accuracy: 0.2467 - val_auc: 0.8692 - val_f1_score: 0.2180 - val_loss: 2.8025 - val_precision: 0.8387 - val_recall: 0.0867\n",
      "Epoch 70/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 163ms/step - accuracy: 0.2319 - auc: 0.8648 - f1_score: 0.1148 - loss: 2.7575 - precision: 0.7710 - recall: 0.1267 - val_accuracy: 0.2548 - val_auc: 0.8716 - val_f1_score: 0.2247 - val_loss: 2.7820 - val_precision: 0.8308 - val_recall: 0.0900\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - accuracy: 0.2995 - auc: 0.8876 - f1_score: 0.1369 - loss: 2.5955 - precision: 0.8171 - recall: 0.1126\n",
      "VGG19 Final Accuracy: 0.2548\n",
      "Training ResNet50\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 03:29:28.322848: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5062_0', 112 bytes spill stores, 224 bytes spill loads\n",
      "\n",
      "2026-01-03 03:29:28.354969: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5730', 68 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2026-01-03 03:29:28.458403: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5062', 220 bytes spill stores, 576 bytes spill loads\n",
      "\n",
      "2026-01-03 03:29:28.492281: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5730', 60 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2026-01-03 03:29:28.496060: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5062_0', 204 bytes spill stores, 204 bytes spill loads\n",
      "\n",
      "2026-01-03 03:29:28.503026: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5730', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.0674 - auc: 0.5524 - f1_score: 0.0084 - loss: 4.9190 - precision: 0.1199 - recall: 0.0455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 03:29:48.020965: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5062_0', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-01-03 03:29:48.204214: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5730', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2026-01-03 03:29:48.325645: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5062', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2026-01-03 03:29:48.369804: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5730', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2026-01-03 03:29:48.499512: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5730', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 134ms/step - accuracy: 0.0670 - auc: 0.5517 - f1_score: 0.0083 - loss: 4.9148 - precision: 0.1197 - recall: 0.0451 - val_accuracy: 0.0200 - val_auc: 0.5001 - val_f1_score: 7.8534e-04 - val_loss: 3.9141 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0955 - auc: 0.6471 - f1_score: 0.0031 - loss: 3.8734 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5002 - val_f1_score: 7.8534e-04 - val_loss: 3.9139 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0955 - auc: 0.6446 - f1_score: 0.0031 - loss: 3.8748 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5002 - val_f1_score: 7.8534e-04 - val_loss: 3.9138 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - accuracy: 0.1028 - auc: 0.6442 - f1_score: 0.0059 - loss: 3.8487 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5001 - val_f1_score: 7.8483e-04 - val_loss: 3.9137 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0955 - auc: 0.6590 - f1_score: 0.0030 - loss: 3.8750 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5001 - val_f1_score: 7.8483e-04 - val_loss: 3.9135 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0955 - auc: 0.6575 - f1_score: 0.0029 - loss: 3.8765 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5002 - val_f1_score: 7.8483e-04 - val_loss: 3.9134 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0955 - auc: 0.6564 - f1_score: 0.0029 - loss: 3.8779 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5003 - val_f1_score: 7.8508e-04 - val_loss: 3.9132 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0955 - auc: 0.6404 - f1_score: 0.0031 - loss: 3.8915 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5001 - val_f1_score: 7.8560e-04 - val_loss: 3.9132 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0981 - auc: 0.6908 - f1_score: 0.0048 - loss: 3.7894 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5002 - val_f1_score: 7.8534e-04 - val_loss: 3.9130 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0965 - auc: 0.6545 - f1_score: 0.0033 - loss: 3.8834 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5003 - val_f1_score: 7.8508e-04 - val_loss: 3.9128 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.0960 - auc: 0.6530 - f1_score: 0.0032 - loss: 3.8845 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5003 - val_f1_score: 7.8818e-04 - val_loss: 3.9128 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0970 - auc: 0.6347 - f1_score: 0.0035 - loss: 3.9025 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5000 - val_f1_score: 7.8508e-04 - val_loss: 3.9129 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0960 - auc: 0.6518 - f1_score: 0.0032 - loss: 3.8869 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5000 - val_f1_score: 7.8534e-04 - val_loss: 3.9131 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0955 - auc: 0.6501 - f1_score: 0.0029 - loss: 3.8893 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5000 - val_f1_score: 7.8508e-04 - val_loss: 3.9131 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0960 - auc: 0.6485 - f1_score: 0.0032 - loss: 3.8881 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5000 - val_f1_score: 7.8560e-04 - val_loss: 3.9133 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0960 - auc: 0.6460 - f1_score: 0.0032 - loss: 3.8890 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5001 - val_f1_score: 7.8663e-04 - val_loss: 3.9137 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 86ms/step - accuracy: 0.0976 - auc: 0.6459 - f1_score: 0.0044 - loss: 3.8890 - precision: 0.9727 - recall: 5.0045e-04 - val_accuracy: 0.0203 - val_auc: 0.5007 - val_f1_score: 0.0014 - val_loss: 3.9135 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0978 - auc: 0.6425 - f1_score: 0.0042 - loss: 3.8879 - precision: 0.7258 - recall: 0.0010 - val_accuracy: 0.0200 - val_auc: 0.5009 - val_f1_score: 7.9025e-04 - val_loss: 3.9135 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0967 - auc: 0.6387 - f1_score: 0.0036 - loss: 3.8903 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0247 - val_auc: 0.5016 - val_f1_score: 0.0050 - val_loss: 3.9117 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0966 - auc: 0.6389 - f1_score: 0.0035 - loss: 3.8887 - precision: 0.7394 - recall: 0.0010 - val_accuracy: 0.0260 - val_auc: 0.5043 - val_f1_score: 0.0052 - val_loss: 3.9099 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0966 - auc: 0.6306 - f1_score: 0.0035 - loss: 3.9000 - precision: 0.6068 - recall: 5.0045e-04 - val_accuracy: 0.0280 - val_auc: 0.5092 - val_f1_score: 0.0056 - val_loss: 3.9050 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.1012 - auc: 0.6534 - f1_score: 0.0055 - loss: 3.8809 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0293 - val_auc: 0.5127 - val_f1_score: 0.0055 - val_loss: 3.9056 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.0720 - auc: 0.6569 - f1_score: 0.0053 - loss: 3.8807 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0240 - val_auc: 0.5064 - val_f1_score: 0.0050 - val_loss: 3.9099 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0482 - auc: 0.6304 - f1_score: 0.0040 - loss: 3.8795 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0243 - val_auc: 0.5101 - val_f1_score: 0.0051 - val_loss: 3.9082 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0482 - auc: 0.6199 - f1_score: 0.0040 - loss: 3.8785 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0230 - val_auc: 0.5201 - val_f1_score: 0.0045 - val_loss: 3.9057 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0522 - auc: 0.6176 - f1_score: 0.0057 - loss: 3.8770 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0240 - val_auc: 0.5092 - val_f1_score: 0.0048 - val_loss: 3.9107 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0284 - auc: 0.6097 - f1_score: 0.0032 - loss: 3.8846 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0210 - val_auc: 0.5124 - val_f1_score: 0.0027 - val_loss: 3.9082 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0266 - auc: 0.6096 - f1_score: 0.0026 - loss: 3.8859 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0217 - val_auc: 0.5133 - val_f1_score: 0.0034 - val_loss: 3.9077 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0293 - auc: 0.6061 - f1_score: 0.0041 - loss: 3.8852 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0230 - val_auc: 0.5262 - val_f1_score: 0.0024 - val_loss: 3.9051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0591 - auc: 0.5515 - f1_score: 0.0094 - loss: 3.9242 - precision: 0.4176 - recall: 0.0010 - val_accuracy: 0.0223 - val_auc: 0.5181 - val_f1_score: 0.0035 - val_loss: 3.9046 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0090 - auc: 0.5973 - f1_score: 0.0022 - loss: 3.8882 - precision: 0.9727 - recall: 5.0045e-04 - val_accuracy: 0.0220 - val_auc: 0.5166 - val_f1_score: 0.0036 - val_loss: 3.9056 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0091 - auc: 0.5916 - f1_score: 0.0024 - loss: 3.8926 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0220 - val_auc: 0.5149 - val_f1_score: 0.0030 - val_loss: 3.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0088 - auc: 0.5912 - f1_score: 0.0019 - loss: 3.8884 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0233 - val_auc: 0.5173 - val_f1_score: 0.0045 - val_loss: 3.9050 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0111 - auc: 0.5833 - f1_score: 0.0036 - loss: 3.8911 - precision: 0.9727 - recall: 0.0010 - val_accuracy: 0.0247 - val_auc: 0.5222 - val_f1_score: 0.0055 - val_loss: 3.9016 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.0102 - auc: 0.5810 - f1_score: 0.0031 - loss: 3.8933 - precision: 0.4106 - recall: 5.0045e-04 - val_accuracy: 0.0273 - val_auc: 0.5227 - val_f1_score: 0.0085 - val_loss: 3.9002 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0114 - auc: 0.5828 - f1_score: 0.0039 - loss: 3.8929 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0267 - val_auc: 0.5210 - val_f1_score: 0.0080 - val_loss: 3.9005 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0100 - auc: 0.5815 - f1_score: 0.0032 - loss: 3.8891 - precision: 0.3045 - recall: 5.0045e-04 - val_accuracy: 0.0263 - val_auc: 0.5277 - val_f1_score: 0.0069 - val_loss: 3.8962 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0098 - auc: 0.5811 - f1_score: 0.0026 - loss: 3.8932 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0263 - val_auc: 0.5265 - val_f1_score: 0.0071 - val_loss: 3.8965 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0090 - auc: 0.5778 - f1_score: 0.0029 - loss: 3.8917 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0253 - val_auc: 0.5274 - val_f1_score: 0.0058 - val_loss: 3.8960 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0094 - auc: 0.5813 - f1_score: 0.0022 - loss: 3.8928 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0250 - val_auc: 0.5325 - val_f1_score: 0.0055 - val_loss: 3.8945 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0024 - auc: 0.5731 - f1_score: 0.0014 - loss: 3.8869 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0253 - val_auc: 0.5384 - val_f1_score: 0.0067 - val_loss: 3.8946 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0073 - auc: 0.5616 - f1_score: 0.0029 - loss: 3.8846 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0240 - val_auc: 0.5347 - val_f1_score: 0.0038 - val_loss: 3.8966 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.0035 - auc: 0.5302 - f1_score: 0.0018 - loss: 3.8970 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0243 - val_auc: 0.5460 - val_f1_score: 0.0037 - val_loss: 3.8931 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0044 - auc: 0.5477 - f1_score: 0.0019 - loss: 3.9016 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0240 - val_auc: 0.5514 - val_f1_score: 0.0025 - val_loss: 3.8909 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.0037 - auc: 0.5321 - f1_score: 0.0013 - loss: 3.8986 - precision: 0.0646 - recall: 8.1522e-05 - val_accuracy: 0.0233 - val_auc: 0.5363 - val_f1_score: 0.0032 - val_loss: 3.8975 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.0017 - auc: 0.5336 - f1_score: 0.0013 - loss: 3.8994 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0240 - val_auc: 0.5549 - val_f1_score: 0.0025 - val_loss: 3.8913 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0016 - auc: 0.5334 - f1_score: 0.0017 - loss: 3.9020 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0240 - val_auc: 0.5652 - val_f1_score: 0.0024 - val_loss: 3.8890 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.0025 - auc: 0.5286 - f1_score: 0.0025 - loss: 3.9115 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0240 - val_auc: 0.5475 - val_f1_score: 0.0041 - val_loss: 3.8929 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0021 - auc: 0.5432 - f1_score: 0.0017 - loss: 3.9000 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0240 - val_auc: 0.5670 - val_f1_score: 0.0030 - val_loss: 3.8891 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0018 - auc: 0.5378 - f1_score: 0.0016 - loss: 3.9038 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0237 - val_auc: 0.5693 - val_f1_score: 0.0024 - val_loss: 3.8894 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0034 - auc: 0.5463 - f1_score: 0.0013 - loss: 3.8988 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0250 - val_auc: 0.5735 - val_f1_score: 0.0031 - val_loss: 3.8952 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 8.3388e-04 - auc: 0.5384 - f1_score: 4.8985e-04 - loss: 3.9095 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0230 - val_auc: 0.5533 - val_f1_score: 0.0024 - val_loss: 3.8929 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0034 - auc: 0.5571 - f1_score: 0.0018 - loss: 3.8928 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0260 - val_auc: 0.5790 - val_f1_score: 0.0035 - val_loss: 3.8993 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.0023 - auc: 0.5377 - f1_score: 0.0015 - loss: 3.9149 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0223 - val_auc: 0.5308 - val_f1_score: 0.0033 - val_loss: 3.9009 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0033 - auc: 0.5605 - f1_score: 0.0018 - loss: 3.8904 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0283 - val_auc: 0.5818 - val_f1_score: 0.0052 - val_loss: 3.9071 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.0023 - auc: 0.5422 - f1_score: 0.0014 - loss: 3.9171 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0233 - val_auc: 0.5395 - val_f1_score: 0.0039 - val_loss: 3.8999 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.0016 - auc: 0.5618 - f1_score: 9.0054e-04 - loss: 3.8964 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0310 - val_auc: 0.5839 - val_f1_score: 0.0052 - val_loss: 3.9105 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.0021 - auc: 0.5908 - f1_score: 4.5747e-04 - loss: 3.9194 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "ResNet50 Final Accuracy: 0.0240\n",
      "Training ResNet101\n",
      "Epoch 1/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 188ms/step - accuracy: 0.0685 - auc: 0.5543 - f1_score: 0.0094 - loss: 4.8091 - precision: 0.1361 - recall: 0.0458 - val_accuracy: 0.0203 - val_auc: 0.4982 - val_f1_score: 0.0014 - val_loss: 3.9218 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0151 - auc: 0.6186 - f1_score: 0.0012 - loss: 3.8712 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0197 - val_auc: 0.5001 - val_f1_score: 7.7200e-04 - val_loss: 3.9143 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 140ms/step - accuracy: 0.0270 - auc: 0.6650 - f1_score: 0.0024 - loss: 3.8694 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5002 - val_f1_score: 7.8508e-04 - val_loss: 3.9141 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0749 - auc: 0.6441 - f1_score: 0.0039 - loss: 3.8739 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5001 - val_f1_score: 7.8508e-04 - val_loss: 3.9140 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.1017 - auc: 0.6432 - f1_score: 0.0048 - loss: 3.8868 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5001 - val_f1_score: 7.8508e-04 - val_loss: 3.9138 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0957 - auc: 0.6612 - f1_score: 0.0032 - loss: 3.8753 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5001 - val_f1_score: 7.8585e-04 - val_loss: 3.9136 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 140ms/step - accuracy: 0.0957 - auc: 0.6597 - f1_score: 0.0032 - loss: 3.8766 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0213 - val_auc: 0.5006 - val_f1_score: 0.0031 - val_loss: 3.9134 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0950 - auc: 0.6424 - f1_score: 0.0039 - loss: 3.8950 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5001 - val_f1_score: 7.8508e-04 - val_loss: 3.9134 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0957 - auc: 0.6527 - f1_score: 0.0032 - loss: 3.8806 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5001 - val_f1_score: 7.8611e-04 - val_loss: 3.9132 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.1000 - auc: 0.6470 - f1_score: 0.0047 - loss: 3.8718 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5000 - val_f1_score: 7.8560e-04 - val_loss: 3.9130 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 140ms/step - accuracy: 0.0957 - auc: 0.6345 - f1_score: 0.0052 - loss: 3.8838 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5004 - val_f1_score: 7.8585e-04 - val_loss: 3.9127 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0713 - auc: 0.6256 - f1_score: 0.0046 - loss: 3.8869 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5006 - val_f1_score: 7.8689e-04 - val_loss: 3.9124 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0681 - auc: 0.6191 - f1_score: 0.0036 - loss: 3.9047 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5003 - val_f1_score: 7.8585e-04 - val_loss: 3.9127 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0254 - auc: 0.6415 - f1_score: 0.0018 - loss: 3.8908 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5005 - val_f1_score: 0.0014 - val_loss: 3.9125 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0262 - auc: 0.6373 - f1_score: 0.0021 - loss: 3.8965 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5003 - val_f1_score: 7.8560e-04 - val_loss: 3.9125 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0254 - auc: 0.6435 - f1_score: 0.0019 - loss: 3.8941 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0200 - val_auc: 0.5003 - val_f1_score: 7.8560e-04 - val_loss: 3.9124 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 147ms/step - accuracy: 0.0256 - auc: 0.6426 - f1_score: 0.0021 - loss: 3.8947 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5003 - val_f1_score: 0.0014 - val_loss: 3.9123 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0256 - auc: 0.6431 - f1_score: 0.0021 - loss: 3.8953 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5005 - val_f1_score: 0.0014 - val_loss: 3.9121 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0256 - auc: 0.6370 - f1_score: 0.0021 - loss: 3.8963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5006 - val_f1_score: 0.0014 - val_loss: 3.9119 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0256 - auc: 0.6381 - f1_score: 0.0021 - loss: 3.8963 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5008 - val_f1_score: 0.0014 - val_loss: 3.9117 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0256 - auc: 0.6348 - f1_score: 0.0021 - loss: 3.8966 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5008 - val_f1_score: 0.0014 - val_loss: 3.9115 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 140ms/step - accuracy: 0.0256 - auc: 0.6319 - f1_score: 0.0020 - loss: 3.8972 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5008 - val_f1_score: 0.0014 - val_loss: 3.9115 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0070 - auc: 0.6358 - f1_score: 8.2948e-04 - loss: 3.8969 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0200 - val_auc: 0.5006 - val_f1_score: 7.8560e-04 - val_loss: 3.9116 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 143ms/step - accuracy: 0.0070 - auc: 0.6310 - f1_score: 9.1769e-04 - loss: 3.8999 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5008 - val_f1_score: 0.0014 - val_loss: 3.9113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0072 - auc: 0.6337 - f1_score: 9.3501e-04 - loss: 3.9000 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5006 - val_f1_score: 0.0014 - val_loss: 3.9117 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0070 - auc: 0.6283 - f1_score: 9.2306e-04 - loss: 3.9015 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5008 - val_f1_score: 0.0014 - val_loss: 3.9113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0068 - auc: 0.6287 - f1_score: 7.0413e-04 - loss: 3.9014 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5008 - val_f1_score: 0.0014 - val_loss: 3.9111 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 5.6070e-04 - auc: 0.6350 - f1_score: 3.4035e-04 - loss: 3.9021 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0200 - val_auc: 0.5005 - val_f1_score: 7.8560e-04 - val_loss: 3.9117 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 1.9093e-04 - auc: 0.6139 - f1_score: 2.1095e-04 - loss: 3.9043 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0200 - val_auc: 0.5009 - val_f1_score: 7.8560e-04 - val_loss: 3.9115 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 1.9093e-04 - auc: 0.6127 - f1_score: 2.1095e-04 - loss: 3.9050 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5009 - val_f1_score: 0.0014 - val_loss: 3.9113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 143ms/step - accuracy: 6.2126e-04 - auc: 0.5983 - f1_score: 6.4465e-04 - loss: 3.9056 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5010 - val_f1_score: 0.0014 - val_loss: 3.9110 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 6.2126e-04 - auc: 0.5829 - f1_score: 6.1130e-04 - loss: 3.9060 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5010 - val_f1_score: 0.0014 - val_loss: 3.9109 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 5.6070e-04 - auc: 0.5696 - f1_score: 4.5273e-04 - loss: 3.9049 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0200 - val_auc: 0.5010 - val_f1_score: 7.8560e-04 - val_loss: 3.9110 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 139ms/step - accuracy: 5.3547e-04 - auc: 0.5458 - f1_score: 6.6289e-04 - loss: 3.9053 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0200 - val_auc: 0.5017 - val_f1_score: 7.8844e-04 - val_loss: 3.9106 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 140ms/step - accuracy: 0.0010 - auc: 0.5447 - f1_score: 7.4793e-04 - loss: 3.9028 - precision: 0.5727 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5017 - val_f1_score: 0.0014 - val_loss: 3.9110 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 140ms/step - accuracy: 6.2368e-04 - auc: 0.5266 - f1_score: 6.6904e-04 - loss: 3.9049 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0200 - val_auc: 0.5015 - val_f1_score: 7.8740e-04 - val_loss: 3.9109 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 8.7534e-04 - auc: 0.5131 - f1_score: 9.2075e-04 - loss: 3.9051 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0200 - val_auc: 0.5026 - val_f1_score: 7.8947e-04 - val_loss: 3.9106 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0018 - auc: 0.5424 - f1_score: 8.5557e-04 - loss: 3.8992 - precision: 0.5727 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5014 - val_f1_score: 0.0014 - val_loss: 3.9114 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 3.0709e-04 - auc: 0.5053 - f1_score: 3.6849e-04 - loss: 3.9079 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5059 - val_f1_score: 0.0012 - val_loss: 3.9098 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0036 - auc: 0.5202 - f1_score: 0.0015 - loss: 3.9108 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5010 - val_f1_score: 0.0014 - val_loss: 3.9119 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 6.8164e-04 - auc: 0.5602 - f1_score: 4.4408e-04 - loss: 3.8436 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5028 - val_f1_score: 0.0013 - val_loss: 3.9113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 4.7845e-04 - auc: 0.4999 - f1_score: 5.5682e-04 - loss: 3.9098 - precision: 0.7409 - recall: 2.4901e-04 - val_accuracy: 0.0207 - val_auc: 0.5070 - val_f1_score: 0.0018 - val_loss: 3.9095 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 2.3431e-04 - auc: 0.5076 - f1_score: 2.0940e-04 - loss: 3.9072 - precision: 0.1682 - recall: 5.8083e-05 - val_accuracy: 0.0203 - val_auc: 0.5114 - val_f1_score: 0.0011 - val_loss: 3.9068 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0012 - auc: 0.5185 - f1_score: 6.8128e-04 - loss: 3.9039 - precision: 0.7409 - recall: 2.4901e-04 - val_accuracy: 0.0203 - val_auc: 0.5084 - val_f1_score: 0.0012 - val_loss: 3.9089 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 138ms/step - accuracy: 8.5557e-04 - auc: 0.5086 - f1_score: 6.9444e-04 - loss: 3.9057 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5111 - val_f1_score: 0.0011 - val_loss: 3.9074 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0014 - auc: 0.5177 - f1_score: 7.3417e-04 - loss: 3.8992 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5100 - val_f1_score: 0.0012 - val_loss: 3.9081 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 9.4360e-04 - auc: 0.5085 - f1_score: 6.4159e-04 - loss: 3.9031 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0203 - val_auc: 0.5104 - val_f1_score: 0.0012 - val_loss: 3.9079 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0010 - auc: 0.5020 - f1_score: 6.1398e-04 - loss: 3.9064 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0210 - val_auc: 0.5169 - val_f1_score: 0.0021 - val_loss: 3.9043 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0018 - auc: 0.5196 - f1_score: 6.0023e-04 - loss: 3.9003 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5120 - val_f1_score: 0.0011 - val_loss: 3.9080 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0012 - auc: 0.4905 - f1_score: 7.6219e-04 - loss: 3.9067 - precision: 0.5727 - recall: 1.9093e-04 - val_accuracy: 0.0220 - val_auc: 0.5237 - val_f1_score: 0.0021 - val_loss: 3.9014 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0029 - auc: 0.4980 - f1_score: 0.0014 - loss: 3.9026 - precision: 0.5727 - recall: 1.9093e-04 - val_accuracy: 0.0210 - val_auc: 0.5192 - val_f1_score: 0.0016 - val_loss: 3.9042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0028 - auc: 0.4903 - f1_score: 0.0015 - loss: 3.9031 - precision: 0.7409 - recall: 1.9093e-04 - val_accuracy: 0.0220 - val_auc: 0.5250 - val_f1_score: 0.0021 - val_loss: 3.9013 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0031 - auc: 0.4928 - f1_score: 0.0012 - loss: 3.8991 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0207 - val_auc: 0.5221 - val_f1_score: 0.0013 - val_loss: 3.9030 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0031 - auc: 0.4860 - f1_score: 0.0014 - loss: 3.8998 - precision: 0.5091 - recall: 1.9093e-04 - val_accuracy: 0.0217 - val_auc: 0.5254 - val_f1_score: 0.0023 - val_loss: 3.9017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0034 - auc: 0.4872 - f1_score: 0.0015 - loss: 3.9000 - precision: 0.2652 - recall: 1.9093e-04 - val_accuracy: 0.0210 - val_auc: 0.5237 - val_f1_score: 0.0015 - val_loss: 3.9023 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0019 - auc: 0.4715 - f1_score: 0.0011 - loss: 3.9084 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0230 - val_auc: 0.5327 - val_f1_score: 0.0026 - val_loss: 3.8965 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0031 - auc: 0.4820 - f1_score: 0.0013 - loss: 3.8979 - precision: 0.2483 - recall: 1.9093e-04 - val_accuracy: 0.0213 - val_auc: 0.5275 - val_f1_score: 0.0017 - val_loss: 3.8997 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0035 - auc: 0.4818 - f1_score: 0.0015 - loss: 3.8950 - precision: 0.4371 - recall: 1.9093e-04 - val_accuracy: 0.0223 - val_auc: 0.5294 - val_f1_score: 0.0022 - val_loss: 3.8985 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 59/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0027 - auc: 0.4799 - f1_score: 0.0011 - loss: 3.8975 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0233 - val_auc: 0.5392 - val_f1_score: 0.0026 - val_loss: 3.8924 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0028 - auc: 0.4791 - f1_score: 0.0013 - loss: 3.8988 - precision: 0.2021 - recall: 1.9093e-04 - val_accuracy: 0.0227 - val_auc: 0.5355 - val_f1_score: 0.0024 - val_loss: 3.8955 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0026 - auc: 0.4897 - f1_score: 0.0013 - loss: 3.8907 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0227 - val_auc: 0.5371 - val_f1_score: 0.0025 - val_loss: 3.8959 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0041 - auc: 0.4518 - f1_score: 0.0013 - loss: 3.8907 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0227 - val_auc: 0.5411 - val_f1_score: 0.0028 - val_loss: 3.8950 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 139ms/step - accuracy: 0.0025 - auc: 0.4568 - f1_score: 0.0011 - loss: 3.8947 - precision: 0.1764 - recall: 1.9093e-04 - val_accuracy: 0.0223 - val_auc: 0.5363 - val_f1_score: 0.0022 - val_loss: 3.8959 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0032 - auc: 0.4675 - f1_score: 0.0013 - loss: 3.8923 - precision: 0.1773 - recall: 1.9093e-04 - val_accuracy: 0.0220 - val_auc: 0.5356 - val_f1_score: 0.0021 - val_loss: 3.8961 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0026 - auc: 0.4715 - f1_score: 0.0012 - loss: 3.8928 - precision: 0.2483 - recall: 1.9093e-04 - val_accuracy: 0.0210 - val_auc: 0.5308 - val_f1_score: 0.0015 - val_loss: 3.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0032 - auc: 0.4757 - f1_score: 0.0012 - loss: 3.8919 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0210 - val_auc: 0.5334 - val_f1_score: 0.0015 - val_loss: 3.8972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 67/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0036 - auc: 0.5390 - f1_score: 0.0016 - loss: 3.8211 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0210 - val_auc: 0.5325 - val_f1_score: 0.0015 - val_loss: 3.8974 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 68/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.0019 - auc: 0.4909 - f1_score: 0.0010 - loss: 3.8956 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0213 - val_auc: 0.5347 - val_f1_score: 0.0023 - val_loss: 3.8955 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 69/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.0017 - auc: 0.4848 - f1_score: 9.4711e-04 - loss: 3.8940 - precision: 0.4530 - recall: 1.9093e-04 - val_accuracy: 0.0220 - val_auc: 0.5411 - val_f1_score: 0.0025 - val_loss: 3.8921 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 70/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 143ms/step - accuracy: 0.0024 - auc: 0.4945 - f1_score: 0.0012 - loss: 3.8909 - precision: 0.5727 - recall: 1.9093e-04 - val_accuracy: 0.0223 - val_auc: 0.5432 - val_f1_score: 0.0029 - val_loss: 3.8895 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 99ms/step - accuracy: 0.0015 - auc: 0.5311 - f1_score: 5.5071e-04 - loss: 3.8856 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "ResNet101 Final Accuracy: 0.0223\n",
      "Training ResNet152\n",
      "Epoch 1/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 262ms/step - accuracy: 0.0648 - auc: 0.5148 - f1_score: 0.0085 - loss: 4.8850 - precision: 0.1456 - recall: 0.0458 - val_accuracy: 0.0203 - val_auc: 0.5001 - val_f1_score: 0.0014 - val_loss: 3.9143 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 198ms/step - accuracy: 0.0965 - auc: 0.6193 - f1_score: 0.0046 - loss: 3.8748 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5001 - val_f1_score: 0.0014 - val_loss: 3.9141 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 198ms/step - accuracy: 0.1226 - auc: 0.6055 - f1_score: 0.0077 - loss: 3.9010 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0207 - val_auc: 0.5002 - val_f1_score: 0.0020 - val_loss: 3.9139 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 201ms/step - accuracy: 0.0971 - auc: 0.6534 - f1_score: 0.0035 - loss: 3.8714 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0207 - val_auc: 0.5004 - val_f1_score: 0.0018 - val_loss: 3.9134 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 200ms/step - accuracy: 0.0977 - auc: 0.6144 - f1_score: 0.0041 - loss: 3.8806 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0210 - val_auc: 0.5002 - val_f1_score: 0.0026 - val_loss: 3.9130 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 198ms/step - accuracy: 0.1027 - auc: 0.6496 - f1_score: 0.0053 - loss: 3.8736 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5001 - val_f1_score: 0.0014 - val_loss: 3.9130 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 202ms/step - accuracy: 0.0963 - auc: 0.6542 - f1_score: 0.0041 - loss: 3.8778 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5000 - val_f1_score: 0.0014 - val_loss: 3.9127 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 199ms/step - accuracy: 0.0978 - auc: 0.6580 - f1_score: 0.0037 - loss: 3.8657 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5001 - val_f1_score: 0.0014 - val_loss: 3.9126 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 199ms/step - accuracy: 0.0974 - auc: 0.6730 - f1_score: 0.0045 - loss: 3.8701 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0210 - val_auc: 0.5009 - val_f1_score: 0.0026 - val_loss: 3.9118 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 203ms/step - accuracy: 0.0964 - auc: 0.6533 - f1_score: 0.0040 - loss: 3.8771 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0213 - val_auc: 0.5007 - val_f1_score: 0.0033 - val_loss: 3.9117 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 198ms/step - accuracy: 0.0967 - auc: 0.6326 - f1_score: 0.0036 - loss: 3.8856 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0217 - val_auc: 0.5007 - val_f1_score: 0.0039 - val_loss: 3.9117 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 236ms/step - accuracy: 0.0957 - auc: 0.6493 - f1_score: 0.0032 - loss: 3.8784 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0220 - val_auc: 0.5012 - val_f1_score: 0.0044 - val_loss: 3.9115 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 196ms/step - accuracy: 0.0956 - auc: 0.6534 - f1_score: 0.0034 - loss: 3.8792 - precision: 0.9773 - recall: 5.2412e-04 - val_accuracy: 0.0220 - val_auc: 0.5011 - val_f1_score: 0.0044 - val_loss: 3.9115 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 197ms/step - accuracy: 0.0955 - auc: 0.6521 - f1_score: 0.0031 - loss: 3.8805 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0210 - val_auc: 0.5007 - val_f1_score: 0.0026 - val_loss: 3.9120 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 237ms/step - accuracy: 0.0996 - auc: 0.6549 - f1_score: 0.0051 - loss: 3.8795 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0210 - val_auc: 0.5010 - val_f1_score: 0.0038 - val_loss: 3.9115 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 197ms/step - accuracy: 0.0684 - auc: 0.6297 - f1_score: 0.0026 - loss: 3.8865 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0207 - val_auc: 0.5009 - val_f1_score: 0.0026 - val_loss: 3.9123 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 197ms/step - accuracy: 0.0686 - auc: 0.6310 - f1_score: 0.0027 - loss: 3.8886 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0210 - val_auc: 0.5016 - val_f1_score: 0.0032 - val_loss: 3.9122 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 201ms/step - accuracy: 0.0458 - auc: 0.6323 - f1_score: 0.0019 - loss: 3.8880 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0207 - val_auc: 0.5036 - val_f1_score: 0.0029 - val_loss: 3.9112 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 199ms/step - accuracy: 0.0457 - auc: 0.6180 - f1_score: 0.0025 - loss: 3.8853 - precision: 0.9773 - recall: 5.2412e-04 - val_accuracy: 0.0207 - val_auc: 0.5018 - val_f1_score: 0.0021 - val_loss: 3.9125 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 198ms/step - accuracy: 0.0458 - auc: 0.5794 - f1_score: 0.0030 - loss: 3.8906 - precision: 0.9773 - recall: 5.2412e-04 - val_accuracy: 0.0207 - val_auc: 0.5044 - val_f1_score: 0.0020 - val_loss: 3.9114 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 201ms/step - accuracy: 0.0476 - auc: 0.6121 - f1_score: 0.0035 - loss: 3.8759 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0207 - val_auc: 0.5035 - val_f1_score: 0.0021 - val_loss: 3.9123 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 199ms/step - accuracy: 0.0283 - auc: 0.5799 - f1_score: 0.0037 - loss: 3.8918 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0207 - val_auc: 0.5071 - val_f1_score: 0.0020 - val_loss: 3.9106 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 198ms/step - accuracy: 0.0311 - auc: 0.5879 - f1_score: 0.0053 - loss: 3.8958 - precision: 0.7258 - recall: 0.0010 - val_accuracy: 0.0203 - val_auc: 0.5050 - val_f1_score: 0.0015 - val_loss: 3.9121 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 201ms/step - accuracy: 0.0015 - auc: 0.5907 - f1_score: 0.0010 - loss: 3.8930 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0203 - val_auc: 0.5059 - val_f1_score: 0.0015 - val_loss: 3.9115 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 198ms/step - accuracy: 0.0023 - auc: 0.5978 - f1_score: 0.0014 - loss: 3.8917 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0207 - val_auc: 0.5055 - val_f1_score: 0.0021 - val_loss: 3.9111 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 201ms/step - accuracy: 0.0017 - auc: 0.6039 - f1_score: 0.0012 - loss: 3.8935 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0223 - val_auc: 0.5068 - val_f1_score: 0.0048 - val_loss: 3.9103 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 203ms/step - accuracy: 0.0026 - auc: 0.6099 - f1_score: 0.0015 - loss: 3.8891 - precision: 0.7303 - recall: 0.0010 - val_accuracy: 0.0220 - val_auc: 0.5064 - val_f1_score: 0.0042 - val_loss: 3.9102 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 199ms/step - accuracy: 0.0061 - auc: 0.6336 - f1_score: 0.0036 - loss: 3.8652 - precision: 0.7922 - recall: 0.0011 - val_accuracy: 0.0223 - val_auc: 0.5107 - val_f1_score: 0.0043 - val_loss: 3.9081 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 198ms/step - accuracy: 0.0021 - auc: 0.6235 - f1_score: 8.5615e-04 - loss: 3.8835 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0217 - val_auc: 0.5035 - val_f1_score: 0.0038 - val_loss: 3.9122 - val_precision: 0.3333 - val_recall: 3.3344e-04\n",
      "Epoch 30/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 202ms/step - accuracy: 0.0024 - auc: 0.6013 - f1_score: 0.0018 - loss: 3.8948 - precision: 0.7583 - recall: 0.0011 - val_accuracy: 0.0217 - val_auc: 0.5086 - val_f1_score: 0.0033 - val_loss: 3.9095 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 199ms/step - accuracy: 0.0035 - auc: 0.6005 - f1_score: 0.0026 - loss: 3.8893 - precision: 0.9773 - recall: 0.0015 - val_accuracy: 0.0223 - val_auc: 0.5133 - val_f1_score: 0.0040 - val_loss: 3.9079 - val_precision: 0.3333 - val_recall: 3.3344e-04\n",
      "Epoch 32/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 199ms/step - accuracy: 0.0014 - auc: 0.6012 - f1_score: 9.8825e-04 - loss: 3.8928 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0223 - val_auc: 0.5115 - val_f1_score: 0.0042 - val_loss: 3.9086 - val_precision: 0.3333 - val_recall: 3.3344e-04\n",
      "Epoch 33/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 203ms/step - accuracy: 0.0025 - auc: 0.5973 - f1_score: 0.0020 - loss: 3.8905 - precision: 0.3361 - recall: 5.5853e-04 - val_accuracy: 0.0220 - val_auc: 0.5134 - val_f1_score: 0.0034 - val_loss: 3.9070 - val_precision: 0.2500 - val_recall: 3.3344e-04\n",
      "Epoch 34/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 198ms/step - accuracy: 0.0038 - auc: 0.6022 - f1_score: 0.0025 - loss: 3.8885 - precision: 0.7047 - recall: 0.0016 - val_accuracy: 0.0227 - val_auc: 0.5115 - val_f1_score: 0.0049 - val_loss: 3.9079 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 198ms/step - accuracy: 0.0051 - auc: 0.5981 - f1_score: 0.0036 - loss: 3.8846 - precision: 0.8089 - recall: 0.0016 - val_accuracy: 0.0230 - val_auc: 0.5152 - val_f1_score: 0.0053 - val_loss: 3.9072 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 201ms/step - accuracy: 0.0054 - auc: 0.5996 - f1_score: 0.0037 - loss: 3.8832 - precision: 0.7994 - recall: 0.0016 - val_accuracy: 0.0227 - val_auc: 0.5123 - val_f1_score: 0.0048 - val_loss: 3.9082 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 199ms/step - accuracy: 0.0041 - auc: 0.5907 - f1_score: 0.0029 - loss: 3.8891 - precision: 0.7341 - recall: 0.0015 - val_accuracy: 0.0217 - val_auc: 0.5144 - val_f1_score: 0.0028 - val_loss: 3.9090 - val_precision: 0.2000 - val_recall: 3.3344e-04\n",
      "Epoch 38/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 199ms/step - accuracy: 0.0032 - auc: 0.5968 - f1_score: 0.0019 - loss: 3.8899 - precision: 0.0841 - recall: 1.1617e-04 - val_accuracy: 0.0230 - val_auc: 0.5147 - val_f1_score: 0.0051 - val_loss: 3.9098 - val_precision: 0.3333 - val_recall: 3.3344e-04\n",
      "Epoch 39/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 200ms/step - accuracy: 0.0042 - auc: 0.5953 - f1_score: 0.0025 - loss: 3.8860 - precision: 0.4820 - recall: 7.8990e-04 - val_accuracy: 0.0223 - val_auc: 0.5138 - val_f1_score: 0.0042 - val_loss: 3.9138 - val_precision: 0.3333 - val_recall: 3.3344e-04\n",
      "Epoch 40/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 198ms/step - accuracy: 0.0031 - auc: 0.5707 - f1_score: 0.0020 - loss: 3.8945 - precision: 0.3374 - recall: 6.4029e-04 - val_accuracy: 0.0220 - val_auc: 0.5163 - val_f1_score: 0.0030 - val_loss: 3.9101 - val_precision: 0.3333 - val_recall: 3.3344e-04\n",
      "Epoch 41/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 199ms/step - accuracy: 0.0030 - auc: 0.5707 - f1_score: 0.0020 - loss: 3.8870 - precision: 0.3641 - recall: 5.8220e-04 - val_accuracy: 0.0227 - val_auc: 0.5174 - val_f1_score: 0.0043 - val_loss: 3.9087 - val_precision: 0.2500 - val_recall: 3.3344e-04\n",
      "Epoch 42/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 201ms/step - accuracy: 0.0021 - auc: 0.5739 - f1_score: 0.0013 - loss: 3.8860 - precision: 0.3489 - recall: 7.8990e-04 - val_accuracy: 0.0233 - val_auc: 0.5184 - val_f1_score: 0.0056 - val_loss: 3.9121 - val_precision: 0.3333 - val_recall: 3.3344e-04\n",
      "Epoch 43/70\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 199ms/step - accuracy: 0.0024 - auc: 0.5663 - f1_score: 0.0014 - loss: 3.8862 - precision: 0.4102 - recall: 0.0011 - val_accuracy: 0.0233 - val_auc: 0.5191 - val_f1_score: 0.0055 - val_loss: 3.9092 - val_precision: 0.3333 - val_recall: 3.3344e-04\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 139ms/step - accuracy: 0.0209 - auc: 0.6216 - f1_score: 0.0022 - loss: 3.8943 - precision: 0.3632 - recall: 0.0012\n",
      "ResNet152 Final Accuracy: 0.0220\n"
     ]
    }
   ],
   "source": [
    "model_list = ['VGG16', 'VGG19', 'ResNet50', 'ResNet101', 'ResNet152']\n",
    "history_dict = {}\n",
    "results = {}\n",
    "EPOCHS = 70\n",
    "\n",
    "for model_name in model_list:\n",
    "    print(f\"Training {model_name}\")\n",
    "    model = build_model(model_name)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall', 'f1_score', 'auc']\n",
    "    )\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_ds,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    history_dict[model_name] = history.history\n",
    "    \n",
    "    eval_results = model.evaluate(test_ds)\n",
    "    # eval_results = [loss, accuracy, precision, recall, f1_score, auc]\n",
    "    acc = eval_results[1]\n",
    "    results[model_name] = acc\n",
    "    print(f\"{model_name} Final Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    # 釋放記憶體\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e07a0d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 繪製 Accuracy 比較長條圖\n",
    "names = list(results.keys())\n",
    "accuracies = list(results.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(names, accuracies, color=['blue', 'orange', 'green', 'red', 'purple'])\n",
    "plt.ylim(0, 1.0)\n",
    "plt.title('Comparison of CNN Models (Accuracy)')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# 在長條圖上標示數值\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 3), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-venv)",
   "language": "python",
   "name": "tf-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
