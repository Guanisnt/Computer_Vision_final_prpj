{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e71083b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 22:07:18.685588: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-03 22:07:18.849565: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767449238.925554   30139 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767449238.946229   30139 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-03 22:07:19.117686: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import resnet, vgg16, vgg19\n",
    "\n",
    "# 預處理函數對照表\n",
    "PREPROCESS_FN = {\n",
    "    'VGG16': vgg16.preprocess_input,\n",
    "    'VGG19': vgg19.preprocess_input,\n",
    "    'ResNet50': resnet.preprocess_input,\n",
    "    'ResNet101': resnet.preprocess_input,\n",
    "    'ResNet152': resnet.preprocess_input,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a65e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767449243.059324   30139 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "IMG_FOLDER = '/mnt/f/course/computer_vision/final_proj_img/final_proj_img/pic/'\n",
    "TXT_FOLDER = '/mnt/f/course/computer_vision/txt/'\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16  # 降低 batch size 以節省 GPU 記憶體\n",
    "\n",
    "# 資料增強層\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.15),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d846f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading name.txt from: /mnt/f/course/computer_vision/txt/name.txt\n",
      "Detected 50 classes.\n",
      "Warning: File not found: /mnt/f/course/computer_vision/final_proj_img/final_proj_img/pic/Planet/Planet_199.jpg\n",
      "Warning: File not found: /mnt/f/course/computer_vision/final_proj_img/final_proj_img/pic/Planet/Planet_200.jpg\n",
      "Total missing files: 2\n",
      "Training Data: 6999 images\n",
      "Testing Data: 2999 images\n",
      "Ready for ResNet/VGG training!\n"
     ]
    }
   ],
   "source": [
    "def load_dataset_from_name_txt(img_folder, txt_folder):\n",
    "    filename_list = []\n",
    "    class_name_list = []\n",
    "    \n",
    "    # 1. 讀取 name.txt\n",
    "    # 格式: \"AncestorDinoArt_001.jpg AncestorDinoArt\"\n",
    "    name_txt_path = os.path.join(txt_folder, 'name.txt')\n",
    "    print(f\"Reading name.txt from: {name_txt_path}\")\n",
    "    \n",
    "    with open(name_txt_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                filename_list.append(parts[0])      # e.g., AncestorDinoArt_001.jpg\n",
    "                class_name_list.append(parts[1])    # e.g., AncestorDinoArt (這也是資料夾名稱)\n",
    "    \n",
    "    # 2. 建立標籤對照表\n",
    "    unique_classes = sorted(list(set(class_name_list)))\n",
    "    class_to_idx = {name: i for i, name in enumerate(unique_classes)}\n",
    "    print(f\"Detected {len(unique_classes)} classes.\")\n",
    "\n",
    "    # 3. 讀取 query.txt (注意：這裡假設 query.txt 是 1-based index)\n",
    "    query_txt_path = os.path.join(txt_folder, 'query.txt')\n",
    "    with open(query_txt_path, 'r') as f:\n",
    "        test_indices = set([int(line.strip()) - 1 for line in f])\n",
    "\n",
    "    # 4. 分裝 Train / Test\n",
    "    train_paths = []\n",
    "    train_labels = []\n",
    "    test_paths = []\n",
    "    test_labels = []\n",
    "\n",
    "    missing_count = 0\n",
    "\n",
    "    for idx, filename in enumerate(filename_list):\n",
    "        class_name = class_name_list[idx]\n",
    "        \n",
    "        # --- [關鍵修正] 路徑加入類別資料夾 ---\n",
    "        # 舊路徑: pic/AncestorDinoArt_001.jpg (錯誤)\n",
    "        # 新路徑: pic/AncestorDinoArt/AncestorDinoArt_001.jpg (正確)\n",
    "        full_path = os.path.join(img_folder, class_name, filename)\n",
    "        \n",
    "        label_idx = class_to_idx[class_name]\n",
    "        \n",
    "        # 檢查檔案是否存在\n",
    "        if not os.path.exists(full_path):\n",
    "            if missing_count < 5: # 只印出前 5 個錯誤以免洗版\n",
    "                print(f\"Warning: File not found: {full_path}\")\n",
    "            missing_count += 1\n",
    "            continue\n",
    "\n",
    "        if idx in test_indices:\n",
    "            test_paths.append(full_path)\n",
    "            test_labels.append(label_idx)\n",
    "        else:\n",
    "            train_paths.append(full_path)\n",
    "            train_labels.append(label_idx)\n",
    "\n",
    "    if missing_count > 0:\n",
    "        print(f\"Total missing files: {missing_count}\")\n",
    "    else:\n",
    "        print(\"All files found successfully!\")\n",
    "\n",
    "    return (train_paths, train_labels), (test_paths, test_labels), len(unique_classes)\n",
    "\n",
    "# --- 執行讀取測試 ---\n",
    "(tr_x, tr_y), (te_x, te_y), num_classes = load_dataset_from_name_txt(IMG_FOLDER, TXT_FOLDER)\n",
    "\n",
    "print(f\"Training Data: {len(tr_x)} images\")\n",
    "print(f\"Testing Data: {len(te_x)} images\")\n",
    "\n",
    "# 建立 tf.data Pipeline (基礎預處理，不含模型特定預處理)\n",
    "def preprocess_base(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    # 將標籤轉換為 one-hot 編碼\n",
    "    label_onehot = tf.one_hot(label, depth=num_classes)\n",
    "    return img, label_onehot\n",
    "\n",
    "# 建立基礎資料集 (不做模型特定預處理，會在模型中處理)\n",
    "train_paths_ds = tf.data.Dataset.from_tensor_slices((tr_x, tr_y))\n",
    "train_ds_base = train_paths_ds.shuffle(buffer_size=len(tr_x)).map(preprocess_base, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds_base = train_ds_base.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_paths_ds = tf.data.Dataset.from_tensor_slices((te_x, te_y))\n",
    "test_ds_base = test_paths_ds.map(preprocess_base, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds_base = test_ds_base.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Ready for ResNet/VGG training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d77392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50, ResNet101, ResNet152, VGG16, VGG19\n",
    "from tensorflow.keras import layers, models, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0817077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_name, fine_tune=False, fine_tune_at=0):\n",
    "    \"\"\"\n",
    "    建構遷移學習模型\n",
    "    \n",
    "    Args:\n",
    "        model_name: 模型名稱\n",
    "        fine_tune: 是否進行 fine-tuning\n",
    "        fine_tune_at: 從第幾層開始解凍 (0 = 全部凍結)\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    \n",
    "    # 資料增強 (只在訓練時套用)\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    # 套用模型特定的預處理\n",
    "    preprocess_fn = PREPROCESS_FN[model_name]\n",
    "    x = preprocess_fn(x)\n",
    "    \n",
    "    if model_name == 'ResNet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'ResNet101':\n",
    "        base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'ResNet152':\n",
    "        base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'VGG19':\n",
    "        base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "    # 凍結 base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # 如果要 fine-tune，解凍部分層\n",
    "    if fine_tune and fine_tune_at > 0:\n",
    "        base_model.trainable = True\n",
    "        # 凍結 fine_tune_at 之前的層\n",
    "        for layer in base_model.layers[:fine_tune_at]:\n",
    "            layer.trainable = False\n",
    "        print(f\"Fine-tuning from layer {fine_tune_at}, total layers: {len(base_model.layers)}\")\n",
    "    \n",
    "    x = base_model(x, training=False)  # training=False 確保 BN 層使用預訓練統計值\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = layers.Dropout(0.5)(x)  # 增加 dropout 防止過擬合\n",
    "    x = layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model, base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c29b8606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training VGG16\n",
      "============================================================\n",
      "\n",
      "[Phase 1] Training top layers only (frozen base model)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767449269.480793   30242 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2026-01-03 22:07:50.316644: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 112ms/step - accuracy: 0.2747 - loss: 10.4013 - val_accuracy: 0.8263 - val_loss: 4.4214 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 111ms/step - accuracy: 0.6701 - loss: 4.5096 - val_accuracy: 0.8429 - val_loss: 2.7285 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 111ms/step - accuracy: 0.7407 - loss: 2.9184 - val_accuracy: 0.8823 - val_loss: 1.9220 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 107ms/step - accuracy: 0.7436 - loss: 2.2922 - val_accuracy: 0.8803 - val_loss: 1.6586 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 109ms/step - accuracy: 0.7630 - loss: 2.0286 - val_accuracy: 0.8860 - val_loss: 1.4856 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 107ms/step - accuracy: 0.7670 - loss: 1.8892 - val_accuracy: 0.8773 - val_loss: 1.4522 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 110ms/step - accuracy: 0.7475 - loss: 1.8921 - val_accuracy: 0.8736 - val_loss: 1.4453 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 106ms/step - accuracy: 0.7711 - loss: 1.7973 - val_accuracy: 0.8780 - val_loss: 1.4729 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 107ms/step - accuracy: 0.7608 - loss: 1.8761 - val_accuracy: 0.8730 - val_loss: 1.4798 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 110ms/step - accuracy: 0.7660 - loss: 1.8613 - val_accuracy: 0.8636 - val_loss: 1.4742 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 107ms/step - accuracy: 0.8084 - loss: 1.5973 - val_accuracy: 0.9080 - val_loss: 1.1022 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 112ms/step - accuracy: 0.8325 - loss: 1.3208 - val_accuracy: 0.9046 - val_loss: 1.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 107ms/step - accuracy: 0.8343 - loss: 1.2106 - val_accuracy: 0.9016 - val_loss: 0.9885 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 110ms/step - accuracy: 0.8342 - loss: 1.1913 - val_accuracy: 0.8980 - val_loss: 0.9469 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 112ms/step - accuracy: 0.8316 - loss: 1.1763 - val_accuracy: 0.9046 - val_loss: 0.9359 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 121ms/step - accuracy: 0.8429 - loss: 1.1514 - val_accuracy: 0.9053 - val_loss: 0.9113 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 119ms/step - accuracy: 0.8292 - loss: 1.1538 - val_accuracy: 0.9036 - val_loss: 0.9113 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 122ms/step - accuracy: 0.8370 - loss: 1.1378 - val_accuracy: 0.8956 - val_loss: 0.9399 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 118ms/step - accuracy: 0.8341 - loss: 1.1178 - val_accuracy: 0.9066 - val_loss: 0.8853 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 122ms/step - accuracy: 0.8275 - loss: 1.1362 - val_accuracy: 0.9063 - val_loss: 0.8923 - learning_rate: 5.0000e-04\n",
      "\n",
      "[Phase 2] Fine-tuning from layer 15\n",
      "Epoch 1/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 119ms/step - accuracy: 0.8690 - loss: 0.9905 - val_accuracy: 0.9220 - val_loss: 0.8344 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 121ms/step - accuracy: 0.8912 - loss: 0.9065 - val_accuracy: 0.9273 - val_loss: 0.8103 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 118ms/step - accuracy: 0.9067 - loss: 0.8428 - val_accuracy: 0.9283 - val_loss: 0.8096 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 113ms/step - accuracy: 0.9086 - loss: 0.8135 - val_accuracy: 0.9356 - val_loss: 0.7732 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 113ms/step - accuracy: 0.9272 - loss: 0.7735 - val_accuracy: 0.9340 - val_loss: 0.7647 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 118ms/step - accuracy: 0.9326 - loss: 0.7402 - val_accuracy: 0.9373 - val_loss: 0.7633 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 113ms/step - accuracy: 0.9391 - loss: 0.7244 - val_accuracy: 0.9320 - val_loss: 0.7957 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 121ms/step - accuracy: 0.9433 - loss: 0.6960 - val_accuracy: 0.9400 - val_loss: 0.7330 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 118ms/step - accuracy: 0.9439 - loss: 0.6905 - val_accuracy: 0.9343 - val_loss: 0.7829 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 121ms/step - accuracy: 0.9486 - loss: 0.6671 - val_accuracy: 0.9373 - val_loss: 0.7380 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 118ms/step - accuracy: 0.9511 - loss: 0.6636 - val_accuracy: 0.9386 - val_loss: 0.7417 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 121ms/step - accuracy: 0.9549 - loss: 0.6313 - val_accuracy: 0.9350 - val_loss: 0.7302 - learning_rate: 1.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 117ms/step - accuracy: 0.9578 - loss: 0.6198 - val_accuracy: 0.9396 - val_loss: 0.7232 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 122ms/step - accuracy: 0.9497 - loss: 0.6335 - val_accuracy: 0.9413 - val_loss: 0.7262 - learning_rate: 1.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 118ms/step - accuracy: 0.9592 - loss: 0.5994 - val_accuracy: 0.9430 - val_loss: 0.7077 - learning_rate: 1.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 121ms/step - accuracy: 0.9646 - loss: 0.5873 - val_accuracy: 0.9403 - val_loss: 0.7089 - learning_rate: 1.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 122ms/step - accuracy: 0.9662 - loss: 0.5641 - val_accuracy: 0.9420 - val_loss: 0.7066 - learning_rate: 1.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 121ms/step - accuracy: 0.9653 - loss: 0.5640 - val_accuracy: 0.9423 - val_loss: 0.6931 - learning_rate: 1.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 118ms/step - accuracy: 0.9712 - loss: 0.5379 - val_accuracy: 0.9423 - val_loss: 0.6779 - learning_rate: 1.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 123ms/step - accuracy: 0.9666 - loss: 0.5385 - val_accuracy: 0.9433 - val_loss: 0.6863 - learning_rate: 1.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 122ms/step - accuracy: 0.9699 - loss: 0.5285 - val_accuracy: 0.9436 - val_loss: 0.6727 - learning_rate: 1.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 119ms/step - accuracy: 0.9682 - loss: 0.5242 - val_accuracy: 0.9446 - val_loss: 0.6765 - learning_rate: 1.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 123ms/step - accuracy: 0.9708 - loss: 0.5093 - val_accuracy: 0.9450 - val_loss: 0.6616 - learning_rate: 1.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 127ms/step - accuracy: 0.9719 - loss: 0.5116 - val_accuracy: 0.9373 - val_loss: 0.7123 - learning_rate: 1.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 130ms/step - accuracy: 0.9738 - loss: 0.4940 - val_accuracy: 0.9423 - val_loss: 0.6748 - learning_rate: 1.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 135ms/step - accuracy: 0.9768 - loss: 0.4748 - val_accuracy: 0.9413 - val_loss: 0.6633 - learning_rate: 1.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 126ms/step - accuracy: 0.9729 - loss: 0.4823 - val_accuracy: 0.9390 - val_loss: 0.6515 - learning_rate: 1.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 131ms/step - accuracy: 0.9740 - loss: 0.4702 - val_accuracy: 0.9476 - val_loss: 0.6269 - learning_rate: 1.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 131ms/step - accuracy: 0.9759 - loss: 0.4538 - val_accuracy: 0.9433 - val_loss: 0.6154 - learning_rate: 1.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 126ms/step - accuracy: 0.9830 - loss: 0.4373 - val_accuracy: 0.9390 - val_loss: 0.6623 - learning_rate: 1.0000e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 90ms/step - accuracy: 0.9321 - loss: 0.6664\n",
      "\n",
      "VGG16 Final Accuracy: 0.9433\n",
      "Model saved to /home/guan/cuda_test/cv/models/VGG16_finetuned.keras\n",
      "\n",
      "============================================================\n",
      "Training VGG19\n",
      "============================================================\n",
      "\n",
      "[Phase 1] Training top layers only (frozen base model)\n",
      "Epoch 1/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 151ms/step - accuracy: 0.2671 - loss: 10.5577 - val_accuracy: 0.8423 - val_loss: 4.4117 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 148ms/step - accuracy: 0.6744 - loss: 4.4984 - val_accuracy: 0.8570 - val_loss: 2.6795 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 147ms/step - accuracy: 0.7342 - loss: 2.9251 - val_accuracy: 0.8730 - val_loss: 1.9459 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 150ms/step - accuracy: 0.7447 - loss: 2.2950 - val_accuracy: 0.8813 - val_loss: 1.6153 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 150ms/step - accuracy: 0.7752 - loss: 1.9510 - val_accuracy: 0.8873 - val_loss: 1.4832 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 156ms/step - accuracy: 0.7590 - loss: 1.9164 - val_accuracy: 0.8426 - val_loss: 1.5824 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 149ms/step - accuracy: 0.7537 - loss: 1.8385 - val_accuracy: 0.8916 - val_loss: 1.3982 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 149ms/step - accuracy: 0.7609 - loss: 1.8494 - val_accuracy: 0.8830 - val_loss: 1.3868 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 152ms/step - accuracy: 0.7630 - loss: 1.8052 - val_accuracy: 0.8693 - val_loss: 1.4500 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 148ms/step - accuracy: 0.7663 - loss: 1.8395 - val_accuracy: 0.8836 - val_loss: 1.4187 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 148ms/step - accuracy: 0.7577 - loss: 1.8652 - val_accuracy: 0.8660 - val_loss: 1.4388 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 150ms/step - accuracy: 0.8006 - loss: 1.5780 - val_accuracy: 0.9030 - val_loss: 1.0916 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 142ms/step - accuracy: 0.8327 - loss: 1.3212 - val_accuracy: 0.8956 - val_loss: 1.0062 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 139ms/step - accuracy: 0.8264 - loss: 1.2328 - val_accuracy: 0.9046 - val_loss: 0.9538 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 139ms/step - accuracy: 0.8387 - loss: 1.1565 - val_accuracy: 0.9036 - val_loss: 0.9386 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 139ms/step - accuracy: 0.8149 - loss: 1.2086 - val_accuracy: 0.9003 - val_loss: 0.9250 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 139ms/step - accuracy: 0.8245 - loss: 1.1392 - val_accuracy: 0.8963 - val_loss: 0.9096 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 135ms/step - accuracy: 0.8317 - loss: 1.1425 - val_accuracy: 0.9073 - val_loss: 0.8874 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 139ms/step - accuracy: 0.8371 - loss: 1.1048 - val_accuracy: 0.9020 - val_loss: 0.9107 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 138ms/step - accuracy: 0.8283 - loss: 1.1449 - val_accuracy: 0.9053 - val_loss: 0.8698 - learning_rate: 5.0000e-04\n",
      "\n",
      "[Phase 2] Fine-tuning from layer 17\n",
      "Epoch 1/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 140ms/step - accuracy: 0.8620 - loss: 1.0149 - val_accuracy: 0.9180 - val_loss: 0.8499 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 142ms/step - accuracy: 0.8986 - loss: 0.9171 - val_accuracy: 0.9273 - val_loss: 0.7916 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 140ms/step - accuracy: 0.9087 - loss: 0.8522 - val_accuracy: 0.9320 - val_loss: 0.7839 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 140ms/step - accuracy: 0.9145 - loss: 0.8229 - val_accuracy: 0.9320 - val_loss: 0.7933 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 143ms/step - accuracy: 0.9269 - loss: 0.7891 - val_accuracy: 0.9326 - val_loss: 0.7992 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 137ms/step - accuracy: 0.9344 - loss: 0.7477 - val_accuracy: 0.9363 - val_loss: 0.7682 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 138ms/step - accuracy: 0.9344 - loss: 0.7337 - val_accuracy: 0.9356 - val_loss: 0.7634 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 146ms/step - accuracy: 0.9420 - loss: 0.7094 - val_accuracy: 0.9330 - val_loss: 0.7562 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 136ms/step - accuracy: 0.9419 - loss: 0.6986 - val_accuracy: 0.9346 - val_loss: 0.7622 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 136ms/step - accuracy: 0.9480 - loss: 0.6723 - val_accuracy: 0.9363 - val_loss: 0.7421 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 136ms/step - accuracy: 0.9511 - loss: 0.6528 - val_accuracy: 0.9383 - val_loss: 0.7536 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 134ms/step - accuracy: 0.9532 - loss: 0.6329 - val_accuracy: 0.9383 - val_loss: 0.7493 - learning_rate: 1.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 137ms/step - accuracy: 0.9503 - loss: 0.6379 - val_accuracy: 0.9450 - val_loss: 0.7140 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 133ms/step - accuracy: 0.9560 - loss: 0.6078 - val_accuracy: 0.9420 - val_loss: 0.7336 - learning_rate: 1.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 135ms/step - accuracy: 0.9604 - loss: 0.5981 - val_accuracy: 0.9410 - val_loss: 0.7233 - learning_rate: 1.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 136ms/step - accuracy: 0.9663 - loss: 0.5673 - val_accuracy: 0.9383 - val_loss: 0.7240 - learning_rate: 1.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 136ms/step - accuracy: 0.9660 - loss: 0.5673 - val_accuracy: 0.9430 - val_loss: 0.7047 - learning_rate: 1.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 134ms/step - accuracy: 0.9690 - loss: 0.5450 - val_accuracy: 0.9420 - val_loss: 0.7011 - learning_rate: 1.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 136ms/step - accuracy: 0.9708 - loss: 0.5383 - val_accuracy: 0.9430 - val_loss: 0.6835 - learning_rate: 1.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 136ms/step - accuracy: 0.9688 - loss: 0.5404 - val_accuracy: 0.9456 - val_loss: 0.6743 - learning_rate: 1.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 136ms/step - accuracy: 0.9714 - loss: 0.5221 - val_accuracy: 0.9460 - val_loss: 0.6751 - learning_rate: 1.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 136ms/step - accuracy: 0.9701 - loss: 0.5114 - val_accuracy: 0.9466 - val_loss: 0.6830 - learning_rate: 1.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 134ms/step - accuracy: 0.9759 - loss: 0.4952 - val_accuracy: 0.9426 - val_loss: 0.6739 - learning_rate: 1.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 139ms/step - accuracy: 0.9720 - loss: 0.5062 - val_accuracy: 0.9423 - val_loss: 0.6868 - learning_rate: 1.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 139ms/step - accuracy: 0.9756 - loss: 0.4913 - val_accuracy: 0.9420 - val_loss: 0.6585 - learning_rate: 1.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 136ms/step - accuracy: 0.9792 - loss: 0.4647 - val_accuracy: 0.9486 - val_loss: 0.6384 - learning_rate: 1.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 146ms/step - accuracy: 0.9802 - loss: 0.4630 - val_accuracy: 0.9473 - val_loss: 0.6508 - learning_rate: 1.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 134ms/step - accuracy: 0.9780 - loss: 0.4562 - val_accuracy: 0.9533 - val_loss: 0.6059 - learning_rate: 1.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 138ms/step - accuracy: 0.9784 - loss: 0.4500 - val_accuracy: 0.9400 - val_loss: 0.6738 - learning_rate: 1.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 141ms/step - accuracy: 0.9807 - loss: 0.4442 - val_accuracy: 0.9503 - val_loss: 0.6300 - learning_rate: 1.0000e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 98ms/step - accuracy: 0.9409 - loss: 0.6659\n",
      "\n",
      "VGG19 Final Accuracy: 0.9533\n",
      "Model saved to /home/guan/cuda_test/cv/models/VGG19_finetuned.keras\n",
      "\n",
      "============================================================\n",
      "Training ResNet50\n",
      "============================================================\n",
      "\n",
      "[Phase 1] Training top layers only (frozen base model)\n",
      "Epoch 1/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 113ms/step - accuracy: 0.3442 - loss: 9.0758 - val_accuracy: 0.8893 - val_loss: 2.5102 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 109ms/step - accuracy: 0.7197 - loss: 2.8244 - val_accuracy: 0.8970 - val_loss: 1.7869 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 106ms/step - accuracy: 0.7485 - loss: 2.2336 - val_accuracy: 0.9086 - val_loss: 1.5350 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 108ms/step - accuracy: 0.7573 - loss: 2.0336 - val_accuracy: 0.9036 - val_loss: 1.5031 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 106ms/step - accuracy: 0.7580 - loss: 1.9402 - val_accuracy: 0.8590 - val_loss: 1.6053 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 107ms/step - accuracy: 0.7560 - loss: 1.9757 - val_accuracy: 0.8920 - val_loss: 1.4725 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 109ms/step - accuracy: 0.7526 - loss: 1.8950 - val_accuracy: 0.8923 - val_loss: 1.4740 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 105ms/step - accuracy: 0.7526 - loss: 1.9063 - val_accuracy: 0.8770 - val_loss: 1.4968 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 109ms/step - accuracy: 0.7522 - loss: 1.8919 - val_accuracy: 0.8976 - val_loss: 1.4292 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 106ms/step - accuracy: 0.7582 - loss: 1.8787 - val_accuracy: 0.8853 - val_loss: 1.4326 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 113ms/step - accuracy: 0.7456 - loss: 1.9089 - val_accuracy: 0.9026 - val_loss: 1.3825 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 108ms/step - accuracy: 0.7660 - loss: 1.8315 - val_accuracy: 0.8666 - val_loss: 1.4818 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 100ms/step - accuracy: 0.7582 - loss: 1.8696 - val_accuracy: 0.8826 - val_loss: 1.4112 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 104ms/step - accuracy: 0.7569 - loss: 1.8356 - val_accuracy: 0.8986 - val_loss: 1.3921 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 101ms/step - accuracy: 0.8039 - loss: 1.6036 - val_accuracy: 0.9183 - val_loss: 1.0119 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 102ms/step - accuracy: 0.8273 - loss: 1.3012 - val_accuracy: 0.9200 - val_loss: 0.9315 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 105ms/step - accuracy: 0.8347 - loss: 1.1952 - val_accuracy: 0.9190 - val_loss: 0.8892 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 103ms/step - accuracy: 0.8277 - loss: 1.1815 - val_accuracy: 0.9150 - val_loss: 0.9134 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 103ms/step - accuracy: 0.8397 - loss: 1.1578 - val_accuracy: 0.9063 - val_loss: 0.9303 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 103ms/step - accuracy: 0.8308 - loss: 1.1720 - val_accuracy: 0.9246 - val_loss: 0.8645 - learning_rate: 5.0000e-04\n",
      "\n",
      "[Phase 2] Fine-tuning from layer 140\n",
      "Epoch 1/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 147ms/step - accuracy: 0.8186 - loss: 1.2707 - val_accuracy: 0.9393 - val_loss: 0.7968 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.8750 - loss: 1.0399 - val_accuracy: 0.9400 - val_loss: 0.7704 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.8905 - loss: 0.9554 - val_accuracy: 0.9463 - val_loss: 0.7434 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 140ms/step - accuracy: 0.8990 - loss: 0.9226 - val_accuracy: 0.9490 - val_loss: 0.7287 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 138ms/step - accuracy: 0.9053 - loss: 0.8770 - val_accuracy: 0.9517 - val_loss: 0.7138 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 138ms/step - accuracy: 0.9109 - loss: 0.8517 - val_accuracy: 0.9530 - val_loss: 0.6985 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 135ms/step - accuracy: 0.9259 - loss: 0.8020 - val_accuracy: 0.9533 - val_loss: 0.6863 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.9306 - loss: 0.7870 - val_accuracy: 0.9570 - val_loss: 0.6712 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.9349 - loss: 0.7631 - val_accuracy: 0.9580 - val_loss: 0.6599 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 145ms/step - accuracy: 0.9359 - loss: 0.7425 - val_accuracy: 0.9613 - val_loss: 0.6453 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.9450 - loss: 0.7090 - val_accuracy: 0.9587 - val_loss: 0.6355 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.9489 - loss: 0.6821 - val_accuracy: 0.9590 - val_loss: 0.6278 - learning_rate: 1.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 141ms/step - accuracy: 0.9491 - loss: 0.6668 - val_accuracy: 0.9603 - val_loss: 0.6103 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.9560 - loss: 0.6467 - val_accuracy: 0.9630 - val_loss: 0.5979 - learning_rate: 1.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.9596 - loss: 0.6196 - val_accuracy: 0.9633 - val_loss: 0.5868 - learning_rate: 1.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 145ms/step - accuracy: 0.9567 - loss: 0.6130 - val_accuracy: 0.9607 - val_loss: 0.5784 - learning_rate: 1.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.9650 - loss: 0.5878 - val_accuracy: 0.9620 - val_loss: 0.5710 - learning_rate: 1.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.9671 - loss: 0.5669 - val_accuracy: 0.9627 - val_loss: 0.5595 - learning_rate: 1.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.9666 - loss: 0.5537 - val_accuracy: 0.9603 - val_loss: 0.5663 - learning_rate: 1.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 141ms/step - accuracy: 0.9642 - loss: 0.5500 - val_accuracy: 0.9623 - val_loss: 0.5516 - learning_rate: 1.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.9684 - loss: 0.5321 - val_accuracy: 0.9653 - val_loss: 0.5352 - learning_rate: 1.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 149ms/step - accuracy: 0.9677 - loss: 0.5207 - val_accuracy: 0.9637 - val_loss: 0.5225 - learning_rate: 1.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 150ms/step - accuracy: 0.9731 - loss: 0.5013 - val_accuracy: 0.9633 - val_loss: 0.5172 - learning_rate: 1.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 156ms/step - accuracy: 0.9743 - loss: 0.4893 - val_accuracy: 0.9643 - val_loss: 0.5116 - learning_rate: 1.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 167ms/step - accuracy: 0.9750 - loss: 0.4744 - val_accuracy: 0.9650 - val_loss: 0.4973 - learning_rate: 1.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 154ms/step - accuracy: 0.9771 - loss: 0.4625 - val_accuracy: 0.9653 - val_loss: 0.4905 - learning_rate: 1.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 154ms/step - accuracy: 0.9770 - loss: 0.4475 - val_accuracy: 0.9640 - val_loss: 0.4802 - learning_rate: 1.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 154ms/step - accuracy: 0.9776 - loss: 0.4436 - val_accuracy: 0.9640 - val_loss: 0.4710 - learning_rate: 1.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 161ms/step - accuracy: 0.9753 - loss: 0.4384 - val_accuracy: 0.9640 - val_loss: 0.4643 - learning_rate: 1.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 154ms/step - accuracy: 0.9752 - loss: 0.4259 - val_accuracy: 0.9620 - val_loss: 0.4628 - learning_rate: 1.0000e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9546 - loss: 0.5019\n",
      "\n",
      "ResNet50 Final Accuracy: 0.9620\n",
      "Model saved to /home/guan/cuda_test/cv/models/ResNet50_finetuned.keras\n",
      "\n",
      "============================================================\n",
      "Training ResNet101\n",
      "============================================================\n",
      "\n",
      "[Phase 1] Training top layers only (frozen base model)\n",
      "Epoch 1/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 172ms/step - accuracy: 0.3594 - loss: 9.2752 - val_accuracy: 0.8850 - val_loss: 2.6536 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 163ms/step - accuracy: 0.7275 - loss: 2.9133 - val_accuracy: 0.9020 - val_loss: 1.8702 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 159ms/step - accuracy: 0.7584 - loss: 2.2494 - val_accuracy: 0.8946 - val_loss: 1.6029 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 156ms/step - accuracy: 0.7669 - loss: 2.0271 - val_accuracy: 0.9080 - val_loss: 1.5173 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 156ms/step - accuracy: 0.7710 - loss: 1.9553 - val_accuracy: 0.8883 - val_loss: 1.5456 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 158ms/step - accuracy: 0.7636 - loss: 1.9602 - val_accuracy: 0.9076 - val_loss: 1.4816 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 144ms/step - accuracy: 0.7594 - loss: 1.9563 - val_accuracy: 0.8826 - val_loss: 1.5512 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 140ms/step - accuracy: 0.7511 - loss: 1.9752 - val_accuracy: 0.8970 - val_loss: 1.4484 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 136ms/step - accuracy: 0.7740 - loss: 1.8567 - val_accuracy: 0.8886 - val_loss: 1.4674 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 139ms/step - accuracy: 0.7511 - loss: 1.9326 - val_accuracy: 0.9106 - val_loss: 1.4533 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 140ms/step - accuracy: 0.7587 - loss: 1.9522 - val_accuracy: 0.9003 - val_loss: 1.4770 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 141ms/step - accuracy: 0.8138 - loss: 1.6097 - val_accuracy: 0.9370 - val_loss: 1.0499 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 140ms/step - accuracy: 0.8466 - loss: 1.3040 - val_accuracy: 0.9243 - val_loss: 0.9603 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 136ms/step - accuracy: 0.8298 - loss: 1.2616 - val_accuracy: 0.9260 - val_loss: 0.9319 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 140ms/step - accuracy: 0.8402 - loss: 1.2099 - val_accuracy: 0.9380 - val_loss: 0.8908 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 141ms/step - accuracy: 0.8276 - loss: 1.2050 - val_accuracy: 0.9126 - val_loss: 0.9579 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 140ms/step - accuracy: 0.8398 - loss: 1.1887 - val_accuracy: 0.9333 - val_loss: 0.8849 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 140ms/step - accuracy: 0.8303 - loss: 1.1949 - val_accuracy: 0.9236 - val_loss: 0.9023 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 136ms/step - accuracy: 0.8539 - loss: 1.1450 - val_accuracy: 0.9273 - val_loss: 0.8822 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 140ms/step - accuracy: 0.8360 - loss: 1.1798 - val_accuracy: 0.9286 - val_loss: 0.9068 - learning_rate: 5.0000e-04\n",
      "\n",
      "[Phase 2] Fine-tuning from layer 300\n",
      "Epoch 1/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 200ms/step - accuracy: 0.8063 - loss: 1.2996 - val_accuracy: 0.9463 - val_loss: 0.8093 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 188ms/step - accuracy: 0.8815 - loss: 1.0322 - val_accuracy: 0.9550 - val_loss: 0.7783 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 191ms/step - accuracy: 0.8907 - loss: 0.9734 - val_accuracy: 0.9593 - val_loss: 0.7530 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 188ms/step - accuracy: 0.9154 - loss: 0.9020 - val_accuracy: 0.9583 - val_loss: 0.7343 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 185ms/step - accuracy: 0.9187 - loss: 0.8795 - val_accuracy: 0.9593 - val_loss: 0.7162 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 185ms/step - accuracy: 0.9223 - loss: 0.8390 - val_accuracy: 0.9613 - val_loss: 0.7030 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 187ms/step - accuracy: 0.9319 - loss: 0.8024 - val_accuracy: 0.9643 - val_loss: 0.6866 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 188ms/step - accuracy: 0.9442 - loss: 0.7591 - val_accuracy: 0.9630 - val_loss: 0.6752 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 191ms/step - accuracy: 0.9380 - loss: 0.7543 - val_accuracy: 0.9657 - val_loss: 0.6599 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 185ms/step - accuracy: 0.9464 - loss: 0.7267 - val_accuracy: 0.9633 - val_loss: 0.6518 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 193ms/step - accuracy: 0.9506 - loss: 0.6922 - val_accuracy: 0.9660 - val_loss: 0.6396 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 187ms/step - accuracy: 0.9468 - loss: 0.6838 - val_accuracy: 0.9663 - val_loss: 0.6267 - learning_rate: 1.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 188ms/step - accuracy: 0.9545 - loss: 0.6579 - val_accuracy: 0.9677 - val_loss: 0.6083 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 192ms/step - accuracy: 0.9611 - loss: 0.6297 - val_accuracy: 0.9677 - val_loss: 0.6006 - learning_rate: 1.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 186ms/step - accuracy: 0.9572 - loss: 0.6245 - val_accuracy: 0.9690 - val_loss: 0.5831 - learning_rate: 1.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 184ms/step - accuracy: 0.9666 - loss: 0.5882 - val_accuracy: 0.9667 - val_loss: 0.5740 - learning_rate: 1.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 189ms/step - accuracy: 0.9648 - loss: 0.5816 - val_accuracy: 0.9687 - val_loss: 0.5583 - learning_rate: 1.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 195ms/step - accuracy: 0.9669 - loss: 0.5653 - val_accuracy: 0.9670 - val_loss: 0.5555 - learning_rate: 1.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 184ms/step - accuracy: 0.9664 - loss: 0.5491 - val_accuracy: 0.9667 - val_loss: 0.5480 - learning_rate: 1.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 191ms/step - accuracy: 0.9708 - loss: 0.5349 - val_accuracy: 0.9687 - val_loss: 0.5288 - learning_rate: 1.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 190ms/step - accuracy: 0.9693 - loss: 0.5217 - val_accuracy: 0.9667 - val_loss: 0.5252 - learning_rate: 1.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 191ms/step - accuracy: 0.9695 - loss: 0.5068 - val_accuracy: 0.9657 - val_loss: 0.5225 - learning_rate: 1.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 190ms/step - accuracy: 0.9756 - loss: 0.4821 - val_accuracy: 0.9667 - val_loss: 0.5063 - learning_rate: 1.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 197ms/step - accuracy: 0.9739 - loss: 0.4748 - val_accuracy: 0.9683 - val_loss: 0.4952 - learning_rate: 1.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 185ms/step - accuracy: 0.9807 - loss: 0.4549 - val_accuracy: 0.9670 - val_loss: 0.4931 - learning_rate: 1.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 191ms/step - accuracy: 0.9773 - loss: 0.4542 - val_accuracy: 0.9690 - val_loss: 0.4810 - learning_rate: 1.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 189ms/step - accuracy: 0.9780 - loss: 0.4363 - val_accuracy: 0.9700 - val_loss: 0.4635 - learning_rate: 1.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 200ms/step - accuracy: 0.9798 - loss: 0.4236 - val_accuracy: 0.9670 - val_loss: 0.4589 - learning_rate: 1.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 189ms/step - accuracy: 0.9840 - loss: 0.4011 - val_accuracy: 0.9683 - val_loss: 0.4521 - learning_rate: 1.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 198ms/step - accuracy: 0.9824 - loss: 0.3935 - val_accuracy: 0.9683 - val_loss: 0.4407 - learning_rate: 1.0000e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 90ms/step - accuracy: 0.9602 - loss: 0.4796\n",
      "\n",
      "ResNet101 Final Accuracy: 0.9683\n",
      "Model saved to /home/guan/cuda_test/cv/models/ResNet101_finetuned.keras\n",
      "\n",
      "============================================================\n",
      "Training ResNet152\n",
      "============================================================\n",
      "\n",
      "[Phase 1] Training top layers only (frozen base model)\n",
      "Epoch 1/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 203ms/step - accuracy: 0.3864 - loss: 9.2248 - val_accuracy: 0.8930 - val_loss: 2.6863 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 191ms/step - accuracy: 0.7280 - loss: 2.9613 - val_accuracy: 0.8990 - val_loss: 1.8525 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 187ms/step - accuracy: 0.7634 - loss: 2.2140 - val_accuracy: 0.8783 - val_loss: 1.6702 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 191ms/step - accuracy: 0.7680 - loss: 2.0451 - val_accuracy: 0.8850 - val_loss: 1.5656 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 185ms/step - accuracy: 0.7613 - loss: 1.9786 - val_accuracy: 0.9066 - val_loss: 1.4727 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 198ms/step - accuracy: 0.7654 - loss: 1.9528 - val_accuracy: 0.8756 - val_loss: 1.5325 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 237ms/step - accuracy: 0.7583 - loss: 1.9584 - val_accuracy: 0.9016 - val_loss: 1.5108 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 195ms/step - accuracy: 0.7700 - loss: 1.9436 - val_accuracy: 0.9110 - val_loss: 1.4498 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 204ms/step - accuracy: 0.7593 - loss: 1.9105 - val_accuracy: 0.8840 - val_loss: 1.5363 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 207ms/step - accuracy: 0.7484 - loss: 1.9793 - val_accuracy: 0.9026 - val_loss: 1.5029 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 200ms/step - accuracy: 0.7569 - loss: 1.9462 - val_accuracy: 0.8810 - val_loss: 1.5390 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 199ms/step - accuracy: 0.8072 - loss: 1.6522 - val_accuracy: 0.9190 - val_loss: 1.0665 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 187ms/step - accuracy: 0.8420 - loss: 1.2795 - val_accuracy: 0.9260 - val_loss: 0.9626 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 187ms/step - accuracy: 0.8311 - loss: 1.2653 - val_accuracy: 0.9360 - val_loss: 0.8922 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 183ms/step - accuracy: 0.8390 - loss: 1.1804 - val_accuracy: 0.9246 - val_loss: 0.9407 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 193ms/step - accuracy: 0.8408 - loss: 1.2189 - val_accuracy: 0.9213 - val_loss: 0.9261 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 185ms/step - accuracy: 0.8329 - loss: 1.2135 - val_accuracy: 0.9263 - val_loss: 0.9212 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 186ms/step - accuracy: 0.8783 - loss: 1.0636 - val_accuracy: 0.9390 - val_loss: 0.7611 - learning_rate: 2.5000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 192ms/step - accuracy: 0.8849 - loss: 0.9257 - val_accuracy: 0.9443 - val_loss: 0.6975 - learning_rate: 2.5000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 186ms/step - accuracy: 0.8907 - loss: 0.8595 - val_accuracy: 0.9443 - val_loss: 0.6764 - learning_rate: 2.5000e-04\n",
      "\n",
      "[Phase 2] Fine-tuning from layer 480\n",
      "Epoch 1/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 251ms/step - accuracy: 0.8470 - loss: 1.0101 - val_accuracy: 0.9496 - val_loss: 0.6429 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 232ms/step - accuracy: 0.8924 - loss: 0.8472 - val_accuracy: 0.9530 - val_loss: 0.6235 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 216ms/step - accuracy: 0.9109 - loss: 0.7873 - val_accuracy: 0.9553 - val_loss: 0.6084 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 211ms/step - accuracy: 0.9102 - loss: 0.7682 - val_accuracy: 0.9573 - val_loss: 0.5928 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 213ms/step - accuracy: 0.9219 - loss: 0.7234 - val_accuracy: 0.9603 - val_loss: 0.5825 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 214ms/step - accuracy: 0.9373 - loss: 0.6866 - val_accuracy: 0.9597 - val_loss: 0.5752 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 213ms/step - accuracy: 0.9343 - loss: 0.6742 - val_accuracy: 0.9590 - val_loss: 0.5634 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 211ms/step - accuracy: 0.9460 - loss: 0.6447 - val_accuracy: 0.9607 - val_loss: 0.5586 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 213ms/step - accuracy: 0.9488 - loss: 0.6184 - val_accuracy: 0.9627 - val_loss: 0.5473 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 214ms/step - accuracy: 0.9439 - loss: 0.6084 - val_accuracy: 0.9633 - val_loss: 0.5335 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 211ms/step - accuracy: 0.9511 - loss: 0.5830 - val_accuracy: 0.9623 - val_loss: 0.5299 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 215ms/step - accuracy: 0.9548 - loss: 0.5707 - val_accuracy: 0.9630 - val_loss: 0.5208 - learning_rate: 1.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 214ms/step - accuracy: 0.9562 - loss: 0.5547 - val_accuracy: 0.9637 - val_loss: 0.5094 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 214ms/step - accuracy: 0.9606 - loss: 0.5343 - val_accuracy: 0.9640 - val_loss: 0.5032 - learning_rate: 1.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 210ms/step - accuracy: 0.9628 - loss: 0.5200 - val_accuracy: 0.9647 - val_loss: 0.4930 - learning_rate: 1.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 214ms/step - accuracy: 0.9658 - loss: 0.5012 - val_accuracy: 0.9647 - val_loss: 0.4942 - learning_rate: 1.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 214ms/step - accuracy: 0.9682 - loss: 0.4898 - val_accuracy: 0.9640 - val_loss: 0.4845 - learning_rate: 1.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 215ms/step - accuracy: 0.9688 - loss: 0.4758 - val_accuracy: 0.9643 - val_loss: 0.4805 - learning_rate: 1.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 211ms/step - accuracy: 0.9695 - loss: 0.4619 - val_accuracy: 0.9657 - val_loss: 0.4639 - learning_rate: 1.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 220ms/step - accuracy: 0.9687 - loss: 0.4516 - val_accuracy: 0.9640 - val_loss: 0.4632 - learning_rate: 1.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 221ms/step - accuracy: 0.9735 - loss: 0.4456 - val_accuracy: 0.9657 - val_loss: 0.4537 - learning_rate: 1.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 226ms/step - accuracy: 0.9763 - loss: 0.4261 - val_accuracy: 0.9660 - val_loss: 0.4484 - learning_rate: 1.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 221ms/step - accuracy: 0.9786 - loss: 0.4139 - val_accuracy: 0.9670 - val_loss: 0.4447 - learning_rate: 1.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 226ms/step - accuracy: 0.9761 - loss: 0.4116 - val_accuracy: 0.9680 - val_loss: 0.4306 - learning_rate: 1.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 220ms/step - accuracy: 0.9821 - loss: 0.3956 - val_accuracy: 0.9663 - val_loss: 0.4343 - learning_rate: 1.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 221ms/step - accuracy: 0.9809 - loss: 0.3855 - val_accuracy: 0.9667 - val_loss: 0.4236 - learning_rate: 1.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 223ms/step - accuracy: 0.9784 - loss: 0.3844 - val_accuracy: 0.9663 - val_loss: 0.4138 - learning_rate: 1.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 222ms/step - accuracy: 0.9829 - loss: 0.3674 - val_accuracy: 0.9677 - val_loss: 0.4073 - learning_rate: 1.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 227ms/step - accuracy: 0.9816 - loss: 0.3617 - val_accuracy: 0.9690 - val_loss: 0.3997 - learning_rate: 1.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 221ms/step - accuracy: 0.9860 - loss: 0.3488 - val_accuracy: 0.9673 - val_loss: 0.3899 - learning_rate: 1.0000e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 131ms/step - accuracy: 0.9544 - loss: 0.4351\n",
      "\n",
      "ResNet152 Final Accuracy: 0.9673\n",
      "Model saved to /home/guan/cuda_test/cv/models/ResNet152_finetuned.keras\n",
      "\n",
      "============================================================\n",
      "Training Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "model_list = ['VGG16', 'VGG19', 'ResNet50', 'ResNet101', 'ResNet152']\n",
    "\n",
    "# Fine-tune 起始層設定 (從這層開始解凍)\n",
    "FINE_TUNE_LAYERS = {\n",
    "    'VGG16': 15,      # VGG16 有 19 層，解凍最後 4 層\n",
    "    'VGG19': 17,      # VGG19 有 22 層，解凍最後 5 層\n",
    "    'ResNet50': 140,  # ResNet50 有 175 層，解凍最後 35 層\n",
    "    'ResNet101': 300, # ResNet101 有 333 層，解凍最後 33 層\n",
    "    'ResNet152': 480, # ResNet152 有 515 層，解凍最後 35 層\n",
    "}\n",
    "\n",
    "history_dict = {}\n",
    "results = {}\n",
    "EPOCHS_PHASE1 = 20  # 第一階段：只訓練頂層\n",
    "EPOCHS_PHASE2 = 30  # 第二階段：Fine-tuning\n",
    "\n",
    "for model_name in model_list:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # ===== 第一階段：凍結 base model，只訓練頂層 =====\n",
    "    print(f\"\\n[Phase 1] Training top layers only (frozen base model)\")\n",
    "    model, base_model = build_model(model_name, fine_tune=False)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    callbacks_phase1 = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history1 = model.fit(\n",
    "        train_ds_base,\n",
    "        epochs=EPOCHS_PHASE1,\n",
    "        validation_data=test_ds_base,\n",
    "        callbacks=callbacks_phase1\n",
    "    )\n",
    "    \n",
    "    # ===== 第二階段：Fine-tuning =====\n",
    "    print(f\"\\n[Phase 2] Fine-tuning from layer {FINE_TUNE_LAYERS[model_name]}\")\n",
    "    \n",
    "    # 解凍部分 base model 層\n",
    "    base_model.trainable = True\n",
    "    fine_tune_at = FINE_TUNE_LAYERS[model_name]\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # 使用較低的學習率進行 fine-tuning\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),  # 降低學習率\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    callbacks_phase2 = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=8,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=4,\n",
    "            min_lr=1e-7\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history2 = model.fit(\n",
    "        train_ds_base,\n",
    "        epochs=EPOCHS_PHASE2,\n",
    "        validation_data=test_ds_base,\n",
    "        callbacks=callbacks_phase2\n",
    "    )\n",
    "    \n",
    "    # 合併兩階段的 history\n",
    "    combined_history = {}\n",
    "    for key in history1.history.keys():\n",
    "        combined_history[key] = history1.history[key] + history2.history[key]\n",
    "    history_dict[model_name] = combined_history\n",
    "    \n",
    "    # 評估模型\n",
    "    eval_results = model.evaluate(test_ds_base)\n",
    "    acc = eval_results[1]\n",
    "    results[model_name] = acc\n",
    "    print(f\"\\n{model_name} Final Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    # 儲存模型\n",
    "    model.save(f'/home/guan/cuda_test/cv/models/{model_name}_finetuned.keras')\n",
    "    print(f\"Model saved to /home/guan/cuda_test/cv/models/{model_name}_finetuned.keras\")\n",
    "    \n",
    "    # 釋放記憶體\n",
    "    del model, base_model\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e07a0d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 繪製 Accuracy 比較長條圖\n",
    "names = list(results.keys())\n",
    "accuracies = list(results.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(names, accuracies, color=['blue', 'orange', 'green', 'red', 'purple'])\n",
    "plt.ylim(0, 1.0)\n",
    "plt.title('Comparison of CNN Models (Accuracy)')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# 在長條圖上標示數值\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 3), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-venv)",
   "language": "python",
   "name": "tf-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
